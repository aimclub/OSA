{
    "code2flow/code2flowlib/__init__.py": [],
    "code2flow/code2flowlib/dotgenerator.py": [
        {
            "details": {
                "docstring": "'''\n\tWrite the dot file\n\t'''",
                "first_doc": "\"\"\"\nWrites a DOT format file representing a graph composed of nodes, edges, and groups.\n\nArgs:\n    dotFile: The path to the output DOT file.\n    nodes: The collection of nodes to include in the graph.\n    edges: The collection of edges connecting the nodes.\n    groups: The groups or clusters of nodes to be represented in the graph.\n\nReturns:\n    None: This method does not return a value.\n\"\"\"",
                "method_name": "writeDotFile",
                "second_doc": "\"\"\"\nGenerates a DOT format file that visually represents the structure and relationships between nodes, edges, and groups within a network. By creating this file, the method enables further visualization and analysis of the connectivity and organization among the specified elements.\n\nArgs:\n    dotFile (str): The file path where the generated DOT format output will be saved.\n    nodes (iterable): The set of nodes to include in the DOT graph.\n    edges (iterable): The set of edges representing connections between nodes.\n    groups (iterable): Clusters or groupings of nodes to be represented in the graph.\n\nReturns:\n    None: This method writes output to a file and does not return a value.\n\"\"\"",
                "source_code": "with open(dotFile,'w') as outfile:\n\t\toutfile.write(generateDotFile(nodes,edges,groups,hidelegend))"
            },
            "type": "function"
        },
        {
            "details": {
                "docstring": "'''\n\tReturn the string for the entire dotfile\n\tTo be appended:\n\t- A legend\n\t- Nodes\n\t- Edges\n\t- Groups\n\t'''",
                "first_doc": "\"\"\"\nGenerates a DOT language representation of a directed graph.\n\nCreates a string representing the graph in DOT format, including nodes, edges, optional legend, and groupings for use with Graphviz visualization tools.\n\nArgs:\n    nodes: A collection of graph nodes to include in the DOT output.\n    edges: A collection of edges defining connections between the nodes.\n    groups: A collection of group definitions, each representing a subgraph or clustering of nodes.\n    hidelegend: If True, omits the legend subgraph from the generated DOT output.\n\nReturns:\n    A string containing the complete DOT graph representation.\n\"\"\"",
                "method_name": "generateDotFile",
                "second_doc": "\"\"\"\nConstructs a DOT-format string describing a directed graph with customizable nodes, edges, groupings, and an optional legend.\n\nThis method supports the creation of a text-based graph definition, which is useful for programmatically portraying abstract structures and relationships between components. By generating a DOT string, it enables the visualization of dynamic or static system structures for improved insight into their interconnections and hierarchy.\n\nArgs:\n    nodes: An iterable of graph nodes to represent as vertices in the DOT output.\n    edges: An iterable of connections between nodes, each defining a directed edge.\n    groups: An iterable of group definitions for clustering nodes as subgraphs.\n    hidelegend: Boolean indicating whether to exclude the legend section from the output.\n\nReturns:\n    str: The entire graph expressed in DOT language as a string.\n\"\"\"",
                "source_code": "ret = \"digraph G {\\n\"\n\tret +=\"concentrate = true;\"\n\tif not hidelegend:\n\t\tret += \"\"\"\n\t\t\tsubgraph legend{\n\t\t\trank = min;\n\t\t\tlabel = \"legend\";\n\t\t\tLegend [shape=none, margin=0, label = <\n\t\t\t\t<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\"><tr><td>Code2flow Legend</td></tr><tr><td>\n\t\t\t\t<table cellspacing=\"0\">\n\t\t\t\t<tr><td>Regular function</td><td width=\"50px\"></td></tr>\n\t\t\t\t<tr><td>Trunk function (nothing calls this)</td><td bgcolor='coral'></td></tr>\n\t\t\t\t<tr><td>Leaf function (this calls nothing else)</td><td bgcolor='green'></td></tr>\n\t\t\t\t<tr><td>Function call which returns no value</td><td>&#8594;</td></tr>\n\t\t\t\t<tr><td>Function call returns some value</td><td><font color='blue'>&#8594;</font></td></tr>\n\t\t\t\t</table></td></tr></table>\n\t\t\t\t>];}\"\"\"\n\tfor node in nodes:\n\t\tif str(node):\n\t\t\tret += str(node)+';\\n'\n\tfor edge in edges:\n\t\tret += str(edge)+';\\n'\n\t#if False:\n\tfor group in groups:\n\t\tret += str(group)+';\\n'\n\n\tret += '}'\n\n\treturn ret"
            },
            "type": "function"
        }
    ],
    "code2flow/code2flowlib/engine.py": [
        {
            "details": {
                "docstring": "'''\n\tWhen a function calls another function, that is an edge\n\tThis is in the global scope because edges can exist between any node and not just between groups\n\t'''",
                "first_doc": "\"\"\"\nGenerates a list of edges by creating an edge between every pair of nodes where a link exists.\n\nArgs:\n    nodes: A list of node objects to be checked for connections.\n\nReturns:\n    list: A list of Edge objects representing directed connections from one node to another, as determined by the linksTo method.\n\"\"\"",
                "method_name": "generateEdges",
                "second_doc": "\"\"\"\nBuilds a list of directed edges representing connections between nodes based on their defined relationships.\n\nArgs:\n    nodes (list): A list of node objects to evaluate for directed connections.\n\nReturns:\n    list: A list of Edge objects, where each edge indicates that an explicit relationship exists from one node to another as determined by the nodes' linksTo method.\n\nWhy:  \nBy systematically enumerating node-to-node relationships, this method produces a structured representation of connections that can be used to map and visualize how elements within a system interact.\n\"\"\"",
                "source_code": "edges = []\n\tfor node0 in nodes:\n\t\tfor node1 in nodes:\n\t\t\tif DEBUG:\n\t\t\t\tprint '\"%s\" links to \"%s\"?'%(node0.name,node1.name)\n\t\t\tif node0.linksTo(node1):\n\t\t\t\tif DEBUG:\n\t\t\t\t\tprint \"Edge created\"\n\t\t\t\tedges.append(Edge(node0,node1))\n\treturn edges"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitialize a Node instance representing a code definition and set up its identification, scope, search patterns, and metadata for graph construction.\n\nArgs:\n    name (str): The name of the node (e.g., function or method name).\n    definitionString (str): The full definition as a string.\n    source (object): The parsed representation of the code source where the node is defined.\n    fullSource (object or None): The complete source context if different from 'source'.\n    parent (Node or None): The parent node or containing scope.\n    characterPos (int): Character position index where the definition begins.\n    lineNumber (int): Line number in the source where the node is defined.\n    isFileRoot (bool): Indicates if this node represents the root of a file.\n\nReturns:\n    None\n\nWhy:\n    This method constructs essential node metadata and regex patterns for later identification and relationship mapping, enabling effective parsing, searching, and visualization of code structure in subsequent processing steps.\n\"\"\"",
                    "source_code": "self.name = name\n\t\tself.definitionString = definitionString\n\t\tself.source = source\n\t\tself.fullSource=fullSource or source\n\t\tself.parent = parent\n\t\tself.characterPos = characterPos\n\t\tself.lineNumber = lineNumber #The line number the definition is on\n\t\tself.isFileRoot = isFileRoot\n\n\t\t#generate the name patterns for other nodes to search for this one\n\t\tself.pattern = re.compile(r\"(?:\\W|\\A)(%s)\\s*\\(\"%self.name,re.MULTILINE)  # The name pattern which is found by others eg. node()\n\n\t\tself.determineNodeType() # Init node, etc.\n\n\t\tself.sameScopePatterns = self.generateSameScopePatterns()  # The pattern to search for when the other node is in the same scope e.g. self.node()\n\t\tself.namespacePatterns = self.generateAnyScopePatterns() # The pattern to search for with the namespace eg. Node.node()\n\n\t\t#determine whether there are return statements or not\n\t\tself.returns = self.returnPattern.search(self.source.sourceString)\n\n\t\t#increment the identifier\n\t\t#Needed for the sake of a unique node name for graphviz\n\t\tglobal currentUID\n\t\tself.uid = currentUID\n\t\tcurrentUID += 1\n\n\t\t#Assume it is a leaf and a trunk until determined otherwise\n\t\tself.isLeaf = True #it calls nothing else\n\t\tself.isTrunk = True #nothing calls it"
                },
                {
                    "docstring": null,
                    "method_name": "generateSameScopePatterns",
                    "second_doc": "\"\"\"\nCreates a regular expression pattern to match function calls with the same scope as this node. This enables detection of specific function invocation patterns, which is necessary for accurately tracing the relationships and connections between functions in the codebase.\n\nArgs:\n    None\n\nReturns:\n    list: A list containing a compiled regular expression object for matching scoped function calls related to this node.\n\"\"\"",
                    "source_code": "return [re.compile(r\"(?:\\W|\\A)%s\\.%s\\s*\\(\"%(self.sameScopeKeyword,self.name),re.MULTILINE|re.DOTALL)]"
                },
                {
                    "docstring": null,
                    "method_name": "generateAnyScopePatterns",
                    "second_doc": "\"\"\"\nGenerates regex patterns to match any invocation of the current node's fully qualified name in the source code. \n\nThis facilitates detection of where and how this function is called, which is necessary for accurately mapping relationships between functions.\n\nArgs:\n    None\n\nReturns:\n    list: A list containing compiled regular expression patterns for identifying calls to this function.\n\"\"\"",
                    "source_code": "return [\n\t\t\tre.compile(r\"(?:[^a-zA-Z0-9\\.]|\\A)%s\\s*\\(\"%(self.getFullName()),re.MULTILINE|re.DOTALL)\n\t\t\t]"
                },
                {
                    "docstring": null,
                    "method_name": "getNamespace",
                    "second_doc": "\"\"\"\nRetrieves the namespace associated with this node by delegating the call to its parent node. This enables consistent access to contextual information throughout hierarchical structures, which is essential for accurately representing scoped elements in code analysis.\n\nReturns:\n    str: The namespace to which this node belongs, as determined by its parent.\n\"\"\"",
                    "source_code": "return self.parent.getNamespace()"
                },
                {
                    "docstring": "'''\n\t\tDummy meant to be subclassed if we do extra calculations to determine node type\n\t\t'''",
                    "first_doc": "\"\"\"\nDetermines the node type for further calculations. \n\nThis method serves as a placeholder for subclasses that require additional computations to determine the node type.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    None: This method does not return a value.\n\"\"\"",
                    "method_name": "determineNodeType",
                    "second_doc": "\"\"\"\nResets the initialization status of the node.\n\nThis method prepares the node for accurate type assignment in subclasses by explicitly marking it as not yet initialized. Ensuring the correct initialization state is essential for downstream analyses or modifications within the parsing and graph-building process.\n\nArgs:\n    self: Instance of the Node class whose initialization status is being set.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.isInitNode = False"
                },
                {
                    "docstring": "'''\n\t\tReturn the name with the namespace\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the fully qualified name, including the namespace.\n\nThis method constructs the object's full name by prefixing the name with the namespace, separated by a dot. If the namespace contains slashes, only the last segment after the final slash is used.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    str: The fully qualified name, which is the namespace and name concatenated by a dot, or just the name if there is no namespace.\n\"\"\"",
                    "method_name": "getFullName",
                    "second_doc": "\"\"\"\nConstructs and returns the object's full name in a hierarchical format, combining its namespace and local name. This helps uniquely identify the object within a larger structure, supporting disambiguation and clarity when working with multiple components that may share names.\n\nArgs:\n    self: Instance of the Node class.\n\nReturns:\n    str: The hierarchical name composed of the last segment of the namespace (if present) and the object's name, joined by a dot. If no namespace is set, returns only the object's name.\n\"\"\"",
                    "source_code": "namespace = self.getNamespace()\n\t\tif '/' in namespace:\n\t\t\tnamespace = namespace.rsplit('/',1)[1]\n\n\t\treturn namespace+'.'+self.name if namespace else self.name"
                },
                {
                    "docstring": null,
                    "method_name": "linksTo",
                    "second_doc": "\"\"\"\nDetermines and returns the set of outgoing edges (links) from this node to other nodes, representing the relationships or connections in the graph.\n\nRaises:\n    NotImplementedError: This method must be implemented by subclasses to specify node connections.\n    \nReturns:\n    set: A set of nodes that this node directly connects to.\n\"\"\"",
                    "source_code": "raise NotImplementedError"
                },
                {
                    "docstring": null,
                    "method_name": "contains",
                    "second_doc": "\"\"\"\nDetermines whether this node is reachable from another node by checking if the other node has a direct link to this one.\n\nArgs:\n    other (Node): The node from which to check for a link.\n\nReturns:\n    bool: True if there is a direct link from the other node to this node, False otherwise.\n\nThis method is used to establish relationships between nodes and facilitate the construction and analysis of call graphs, enabling insight into how program components are interconnected.\n\"\"\"",
                    "source_code": "return other.linksTo(self)"
                },
                {
                    "docstring": "'''\n\t\tDummy function meant to be subclassed\n\t\tWill contain logic that will determine whether this node can be removed during trimming\n\t\t'''",
                    "first_doc": "\"\"\"\nDetermines whether this node can be considered extraneous and removed during trimming.\n\nThis method is intended to be subclassed. It contains logic that decides if the current node should be removed during a trimming operation.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    bool: False by default, indicating that this node is not considered extraneous. Subclasses may override this behavior.\n\"\"\"",
                    "method_name": "isExtraneous",
                    "second_doc": "\"\"\"\nChecks if the node is unnecessary and should be eliminated when simplifying the node structure.\n\nThis method provides a default implementation to determine node relevance in the trimming process, aiding in the filtering of nodes that do not contribute to the primary relationships or flow structure. It can be overridden in subclasses to customize removal logic.\n\nArgs:\n    self: The instance of the Node class.\n\nReturns:\n    bool: Returns False by default, meaning the node is not marked for removal. Subclasses may override to indicate a node should be trimmed.\n\"\"\"",
                    "source_code": "return False"
                },
                {
                    "docstring": null,
                    "method_name": "_getUID",
                    "second_doc": "\"\"\"\nGenerates a unique identifier string for the node instance, combining a fixed prefix with the object's unique ID.\n\nReturns:\n    str: The unique identifier for this node, used to distinguish nodes in further processing or visualization.\n\"\"\"",
                    "source_code": "return 'node'+str(self.uid)"
                },
                {
                    "docstring": null,
                    "method_name": "_getFileGroup",
                    "second_doc": "\"\"\"\nRetrieves the file group associated with the current node by delegating the request to its parent node.\n\nArgs:\n    None\n\nReturns:\n    The file group object obtained from the parent node.\n\nWhy:\n    This method allows nodes to refer to their hierarchical context for file grouping, ensuring consistent grouping logic and reducing redundancy across the structure.\n\"\"\"",
                    "source_code": "return self.parent._getFileGroup()"
                },
                {
                    "docstring": null,
                    "method_name": "_getFileName",
                    "second_doc": "\"\"\"\nRetrieve the filename associated with the current node by delegating the request to its parent node.\n\nThis approach ensures that filename information is accessed consistently through the node hierarchy, supporting accurate mapping between the visual representation and the underlying source code structure.\n\nReturns:\n    str: The filename associated with the node, as determined by traversing to its parent.\n\"\"\"",
                    "source_code": "return self.parent._getFileName()"
                },
                {
                    "docstring": "'''\n\t\tFor printing to the DOT file\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns a string representation of the object formatted for inclusion in a DOT file.\n\nConstructs a DOT node line including attributes such as label, shape, style, and fill color, based on the object's properties. Highlights nodes as filled with specific colors if the node is a trunk or leaf.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    str: The DOT language representation of the object as a formatted string.\n\"\"\"",
                    "method_name": "__str__",
                    "second_doc": "\"\"\"\nGenerates a DOT language representation of the node, including style and formatting that reflect its structural role, to support accurate and meaningful visualization of code structure.\n\nArgs:\n    self: Instance of the Node class whose visual representation is to be generated.\n\nReturns:\n    str: Formatted string in DOT syntax, encoding the node's label, shape, style, and optional color attributes.\n\"\"\"",
                    "source_code": "attributes = {}\n\n\t\tattributes['label']=\"%d: %s\"%(self.lineNumber,self.getFullName())\n\t\tattributes['shape']=\"rect\"\n\t\tattributes['style']=\"rounded\"\n\t\t#attributes['splines']='ortho'\n\t\tif self.isTrunk:\n\t\t\tattributes['style']+=',filled'\n\t\t\tattributes['fillcolor']='coral'\n\t\telif self.isLeaf:\n\t\t\tattributes['style']+=',filled'\n\t\t\tattributes['fillcolor']='green'\n\n\t\tret = self._getUID()\n\t\tif attributes:\n\t\t\tret += ' [splines=ortho '\n\t\t\tfor a in attributes:\n\t\t\t\tret += '%s = \"%s\" '%(a,attributes[a])\n\t\t\tret += ']'\n\n\t\treturn ret"
                }
            ],
            "name": "Node",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes an Edge object representing a directed connection between two nodes in a function call graph. Sets properties on the nodes to indicate that the calling node is not a leaf and the called node is not a trunk.\n\nArgs:\n    node0: The source node (caller) in the connection.\n    node1: The target node (callee) in the connection.\n\nReturns:\n    None\n\nWhy:\n    This setup helps classify nodes based on their roles in the call graph, which is useful for accurately representing relationships and node types when generating a visual overview of code structure.\n\"\"\"",
                    "source_code": "self.node0 = node0\n\t\tself.node1 = node1\n\n\t\t#When we draw the edge, we know the calling function is definitely not a leaf...\n\t\t#and the called function is definitely not a trunk\n\t\tnode0.isLeaf = False\n\t\tnode1.isTrunk = False"
                },
                {
                    "docstring": "'''\n\t\tFor printing to the DOT file\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns a string representation of the edge in DOT file format.\n\nThis method generates a string describing the connection between two nodes, suitable for use in a DOT graph representation. If the target node has a return value, the edge is styled accordingly.\n\nReturns:\n    str: A formatted string representing the edge between two nodes, with visual style indications if the target node returns a value.\n\"\"\"",
                    "method_name": "__str__",
                    "second_doc": "\"\"\"\nGenerates a DOT-formatted string to represent an edge between two graph nodes.\n\nThis method constructs the textual depiction of a directed connection from one node to another for use in graph visualization tools. If the destination node signifies a return value, the edge's appearance is adjusted to visually reflect this characteristic.\n\nArgs:\n    None\n\nReturns:\n    str: DOT language representation of the edge, with styling applied if the target node indicates a returned value, to aid in distinguishing different types of relationships in the graph.\n\"\"\"",
                    "source_code": "ret = self.node0._getUID() + ' -> ' + self.node1._getUID()\n\t\tif self.node1.returns:\n\t\t\tret += ' [color=\"blue\" penwidth=\"2\"]'\n\t\treturn ret"
                },
                {
                    "docstring": null,
                    "method_name": "hasEndNode",
                    "second_doc": "\"\"\"\nDetermines whether the specified node is the same as the end node of the edge.\n\nArgs:\n    node1: The node to be checked against the end node of this edge.\n\nReturns:\n    bool: True if node1 is the edge's end node; otherwise, False.\n\nThis check helps clarify relationships between nodes in a graph structure representing code elements and their connections, supporting accurate graph construction and analysis of code flow.\n\"\"\"",
                    "source_code": "return node1 == self.node1"
                },
                {
                    "docstring": null,
                    "method_name": "hasStartNode",
                    "second_doc": "\"\"\"\nDetermines whether the given node is the starting point of this edge.\n\nArgs:\n    node0: The node to check against the starting node of this edge.\n\nReturns:\n    bool: True if the provided node matches the starting node of the edge, otherwise False.\n\nThis method helps establish the directionality of connections between nodes, which is crucial for accurately modeling and visualizing relationships within a codebase.\n\"\"\"",
                    "source_code": "return node0 == self.node0"
                }
            ],
            "name": "Edge",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes a Group object representing a logical code structure (such as a function or class) and prepares it for tracking internal nodes, nested groups, and object instantiations and calls within source code.\n\nArgs:\n    name (str): The name of the group.\n    definitionString (str): The code segment that defines the group.\n    source (str): The source code for the group.\n    fullSource (str): The full source text, or source if not provided.\n    parent (Group or None): The parent group, if any.\n    lineNumber (int): The line number where the group is defined.\n\nReturns:\n    None\n\nWhy:\n    This method sets up the necessary data structures and unique identifiers needed to analyze and represent relationships within the code structure, facilitating later visualization and understanding of code flow.\n\"\"\"",
                    "source_code": "self.name = name\n\t\tself.definitionString = definitionString\n\t\tself.source = source\n\t\tself.fullSource = fullSource or source\n\t\tself.parent = parent\n\t\tself.lineNumber = lineNumber\n\n\t\tself.nodes = []\n\t\tself.subgroups = []\n\n\t\t#So that we can track object calls as well like:\n\t\t# a = Obj()\n\t\t# a.b()\n\t\tself.newObjectPattern = self.generateNewObjectPattern()\n\t\tself.newObjectAssignedPattern = self.generateNewObjectAssignedPattern()\n\n\t\t#increment the identifier\n\t\t#Needed for the sake of a unique node name for graphviz\n\t\tglobal currentUID\n\t\tself.uid = currentUID\n\t\tcurrentUID += 1"
                },
                {
                    "docstring": "'''\n\t\t__str__ is for printing to the DOT file\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns a string representation of the object for use in DOT file formatting.\n\nThis method constructs a DOT-format string representing the subgraph, its nodes, visual attributes, and any nested subgroups.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    str: A string in DOT language format describing the subgraph, its nodes, style, and subgroups, suitable for inclusion in a Graphviz DOT file.\n\"\"\"",
                    "method_name": "__str__",
                    "second_doc": "\"\"\"\nGenerates a DOT-format string describing this group, including its nodes, visual attributes, and any nested subgroups, to provide a structured specification for graph visualization tools.\n\nThis method assembles the necessary information so that hierarchical relationships and group styles can be accurately rendered for analysis or documentation purposes.\n\nArgs:\n    self: Group\n        The group instance being represented in DOT format.\n\nReturns:\n    str\n        DOT language string containing group definition, list of nodes, styling information, and recursive representations of any subgroups.\n\"\"\"",
                    "source_code": "#pdb.set_trace()\n\t\tret = 'subgraph '+self._getUID()\n\t\tret += '{\\n'\n\t\tif self.nodes:\n\t\t\tfor node in self.nodes:\n\t\t\t\tret += node._getUID() + ' '\n\t\t\t\t#if node.isFileRoot:\n\t\t\t\t#\tret += \";{rank=source; %s}\"%node._getUID()\n\n\t\t\tret += ';\\n'\n\t\tret += 'label=\"%s\";\\n'%self.name;\n\t\tret += 'style=filled;\\n';\n\t\tret += 'color=black;\\n';\n\t\tret += 'graph[style=dotted];\\n'\n\t\t#pdb.set_trace()\n\t\tfor subgroup in self.subgroups:\n\t\t\tret += str(subgroup)\n\t\tret += '}'\n\t\treturn ret"
                },
                {
                    "docstring": "'''\n\t\tReturns the full string namespace of this group including this groups name\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the full string namespace of this group including the group's name.\n\nReturns:\n    The full string namespace of the group, which currently consists of the group's name.\n\"\"\"",
                    "method_name": "getNamespace",
                    "second_doc": "\"\"\"\nRetrieves the string identifier used to represent this group's scope within the current analysis, allowing for differentiation between groups during code structure parsing.\n\nArgs:\n    None\n\nReturns:\n    str: The string identifier (currently just the group's name) representing the group's scope.\n\"\"\"",
                    "source_code": "#TODO more complex namespaces involving parents and modules\n\t\t#js implements something a bit more complicated already\n\t\t#python uses this\n\n\t\treturn self.name"
                },
                {
                    "docstring": null,
                    "method_name": "trimGroups",
                    "second_doc": "\"\"\"\nTrim the current set of groups maintained by the Group class.\n\nThis method is used to optimize the organization or representation of grouped elements, potentially making subsequent analyses or visualizations more accurate and clear.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "pass"
                },
                {
                    "docstring": null,
                    "method_name": "_generateRootNodeName",
                    "second_doc": "\"\"\"\nConstructs a root node name string for graph visualization, incorporating both the group and frame names to indicate the primary entry point for further analysis.\n\nArgs:\n    name (str, optional): Custom name to override the default group name. If not provided, uses the instance's name attribute.\n\nReturns:\n    str: A formatted string representing the root node in the graph.\n\"\"\"",
                    "source_code": "if not name:\n\t\t\tname = self.name\n\t\treturn \"(%s %s frame (runs on import))\"%(name,self.globalFrameName)"
                },
                {
                    "docstring": "'''\n\t\tPrint the file structure\n\t\tStrictly for debugging right now\n\t\t'''",
                    "first_doc": "\"\"\"\nPrints or returns a dictionary representation of the file structure for debugging purposes.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    dict: A dictionary representing the file structure, mapping names of nodes and subgroups to their corresponding types or sub-structures.\n\"\"\"",
                    "method_name": "_pprint",
                    "second_doc": "\"\"\"\nGenerates a dictionary that outlines the hierarchical structure of nodes and subgroups within the current group, recursively expanding subgroups as nested dictionaries. This facilitates introspection of internal relationships and organization within complex groupings, allowing for easier understanding, debugging, and verification of structural integrity.\n\nArgs:\n    printHere (bool): If True, the dictionary is printed in a readable format; if False, the dictionary is returned.\n\nReturns:\n    dict: A dictionary mapping the names of nodes and subgroups to their types or recursively constructed sub-structures, representing the internal hierarchy.\n\"\"\"",
                    "source_code": "tree = map(lambda x:(x.name,'node'),self.nodes)\n\t\ttree += map(lambda x:(x.name,x._pprint(printHere=False)),self.subgroups)\n\t\tif printHere:\n\t\t\tpprint.pprint(dict(tree))\n\t\telse:\n\t\t\treturn dict(tree)"
                },
                {
                    "docstring": "'''\n\t\tSomething\n\t\t'''",
                    "first_doc": "\"\"\"\nGenerates a unique identifier string for the current instance, applying anonymization if required.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    str: The unique identifier string for this instance.\n\"\"\"",
                    "method_name": "_getUID",
                    "second_doc": "\"\"\"\nConstructs a unique identifier for the group instance to ensure consistent reference, optionally anonymizing details based on privacy settings.\n\nThis method helps maintain reliable naming for groups whether or not the actual group names can be disclosed, supporting tracking or visualization tasks that require unambiguous instance identification.\n\nArgs:\n    self: The Group instance for which the identifier is being generated.\n\nReturns:\n    str: A string uniquely identifying the group instance, anonymized if privacy is enabled.\n\"\"\"",
                    "source_code": "try:\n\t\t\tif self.isAnon:\n\t\t\t\treturn 'clusterANON'+str(self.uid)\n\t\t\telse:\n\t\t\t\traise Exception()\n\t\texcept:\n\t\t\treturn 'cluster'+re.sub(r\"[/\\.\\-\\(\\)=\\s]\",'',self.name)+str(self.uid)"
                },
                {
                    "docstring": "'''\n\t\tEvery node in this namespace and all descendent namespaces\n\t\t'''",
                    "first_doc": "\"\"\"\nRetrieves all nodes in the current namespace and its descendant namespaces.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    list: A combined list of nodes from this namespace and all subgroups (descendant namespaces).\n\"\"\"",
                    "method_name": "_allNodes",
                    "second_doc": "\"\"\"\nRecursively collects all nodes contained within the current group and its nested subgroups, ensuring a comprehensive aggregation of elements for further analysis or processing.\n\nArgs:\n    self: The instance of the Group class.\n\nReturns:\n    list: A list containing all nodes from this group and all descendant subgroups.\n\"\"\"",
                    "source_code": "nodes = self.nodes\n\t\tfor subgroup in self.subgroups:\n\t\t\tnodes += subgroup._allNodes()\n\t\treturn nodes"
                },
                {
                    "docstring": null,
                    "method_name": "_getFileGroup",
                    "second_doc": "\"\"\"\nRecursively traverses up the group hierarchy to locate the topmost file group associated with this instance.\n\nArgs:\n    None\n\nReturns:\n    Group: The root file group instance at the top of the hierarchy.\n    \nWhy:\n    This method ensures that group-level operations or associations are consistently performed at the highest relevant level in the hierarchy, preventing duplication and maintaining a single authoritative reference.\n\"\"\"",
                    "source_code": "if self.parent:\n\t\t\treturn self.parent._getFileGroup()\n\t\telse:\n\t\t\treturn self"
                },
                {
                    "docstring": null,
                    "method_name": "_getFileName",
                    "second_doc": "\"\"\"\nRetrieves the name associated with the file group represented by this instance.\n\nThis is used to identify and label different groups of related functions or code elements, supporting consistent organization during analysis and visualization.\n\nReturns:\n    str: The name of the file group associated with this object.\n\"\"\"",
                    "source_code": "return self._getFileGroup().name"
                }
            ],
            "name": "Group",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": "'''\n\t\tRemove the comments and build the linenumber/file mapping while doing so\n\t\t'''",
                    "first_doc": "\"\"\"\nInitializes a new instance of the class, removing comments from the source string and building a mapping from character positions to line numbers.\n\nArgs:\n    sourceString: The source code string that will be processed to remove comments and build the line number mapping.\n\nClass Fields:\n    sourceString: Holds the processed source code string with comments removed.\n    characterToLineMap: A mapping from character positions to line numbers in the source string.\n    delimLen: The length of the delimiter defined by the instance (self.delimA).\n\nReturns:\n    None\n\"\"\"",
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes the SourceCode instance by sanitizing the input source string\u2014removing comments and string literals\u2014and constructing a mapping from each character position in the code to its corresponding line number. This enables consistent, comment-free source analysis and accurate correlation of code positions to their original locations, facilitating downstream parsing and analysis.\n\nArgs:\n    sourceString (str): The raw source code to be processed.\n    characterToLineMap (dict, optional): An optional precomputed mapping from character positions to line numbers. If not provided, the mapping is built automatically.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.sourceString = sourceString\n\n\t\tif characterToLineMap:\n\t\t\tself.characterToLineMap = characterToLineMap\n\t\telse:\n\t\t\tself.characterToLineMap = {}\n\n\t\t\tself._removeCommentsAndStrings()\n\t\t\tself.sourceString = str(self.sourceString) #convert back to regular python string from mutable string\n\n\t\t\tif DEBUG:\n\t\t\t\t#print 'REMOVED COMMENTS',self\n\t\t\t\twith open('cleanedSource','w') as outfile:\n\t\t\t\t\toutfile.write(self.sourceString)\n\n\t\tself.delimLen = len(self.delimA)"
                },
                {
                    "docstring": null,
                    "method_name": "__len__",
                    "second_doc": "\"\"\"\nReturns the number of characters in the source code string.\n\nThis allows the length of the source code to be easily obtained, which may assist in various processing or analysis tasks that depend on the size of the source input.\n\nReturns:\n    int: The length of the source code string stored in this object.\n\"\"\"",
                    "source_code": "return len(self.sourceString)"
                },
                {
                    "docstring": "'''\n\t\tIf sliced, return a new object with the sourceString and the characterToLineMap sliced by [firstChar:lastChar]\n\n\t\t1. Slice the source string in the obvious way.\n\t\t2. Slice the charactertolinemap\n\t\t\ta. Remove character mappings that are not in between where we are shifting to\n\t\t\tb. Take remaining characterPositions and shift them over by start shift\n\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns a new object with the sourceString and characterToLineMap sliced according to the specified indices or returns a single character for an integer input.\n\nArgs:\n    self: The instance of the object.\n    sl: An integer representing a single character index, or a slice object specifying the start and stop indices for slicing.\n\nReturns:\n    A new object with the sourceString and characterToLineMap adjusted according to the specified slice if a slice is provided; otherwise, returns a single character from sourceString if an integer index is provided.\n\nRaises:\n    Exception: If the argument is not an integer or a valid slice.\n    Exception: If the slice step attribute is set (steps are not supported).\n    Exception: If the slice start index is greater than the stop index.\n\"\"\"",
                    "method_name": "__getitem__",
                    "second_doc": "\"\"\"\nExtracts a substring or a sliced portion of the source code and updates the character-to-line mapping to accurately reflect the new segment, or retrieves a single character at a specified index.\n\nArgs:\n    self: The current instance of the SourceCode object.\n    sl (int or slice): An index to retrieve a single character, or a slice object specifying the range of characters to extract from the source code.\n\nReturns:\n    SourceCode: A new SourceCode object containing the sliced portion of the source and an updated character-to-line map if a slice is provided.\n    str: A single character from the source string if an integer index is provided.\n\nRaises:\n    Exception: If the argument is neither an integer nor a valid slice.\n    Exception: If the provided slice includes a step attribute (steps are unsupported).\n    Exception: If the slice's start index is greater than the stop index.\n\nWhy:\n    This method allows for precise extraction and analysis of code fragments while maintaining an accurate mapping between characters and their original line numbers, supporting further processing or visualization of code structure.\n\"\"\"",
                    "source_code": "if type(sl) == int:\n\t\t\treturn self.sourceString[sl]\n\n\t\tif type(sl) != slice:\n\t\t\traise Exception(\"Slice was not passed\")\n\n\t\tif sl.step and (sl.start or sl.stop):\n\t\t\traise Exception(\"Sourcecode slicing does not support the step attribute (e.g. source[from:to:step] is not supported)\")\n\n\t\tif sl.start is None:\n\t\t\tstart = 0\n\t\telse:\n\t\t\tstart = sl.start\n\n\t\tif sl.stop is None:\n\t\t\tstop = len(self.sourceString)\n\t\telif sl.stop < 0:\n\t\t\tstop = len(self.sourceString)+sl.stop\n\t\telse:\n\t\t\tstop = sl.stop\n\n\t\tif start>stop:\n\t\t\traise Exception(\"Begin slice cannot be greater than end slice. You passed SourceCode[%d:%d]\"%(sl.start,sl.stop))\n\n\t\tret = self.copy()\n\n\t\tret.sourceString = ret.sourceString[start:stop]\n\n\t\t#filter out character mapping we won't be using\n\t\tshiftedCharacterToLineMap = {}\n\t\tcharacterPositions = ret.characterToLineMap.keys()\n\t\tcharacterPositions = filter(lambda p: p>=start and p<=stop,characterPositions)\n\n\t\t#shift existing character mappings to reflect the new start position\n\t\t#If we start with 0, no shifting will take place\n\t\tfor characterPosition in characterPositions:\n\t\t\tshiftedCharacterToLineMap[characterPosition-start] = ret.characterToLineMap[characterPosition]\n\n\t\t#we need this to be sure that we can always get the line number no matter where we splice\n\t\tshiftedCharacterToLineMap[0] = self.getLineNumber(start)\n\n\t\tret.characterToLineMap = shiftedCharacterToLineMap\n\t\treturn ret"
                },
                {
                    "docstring": "'''\n\t\tAdd two pieces of sourcecode together shifting the character to line map appropriately\n\t\t'''",
                    "first_doc": "\"\"\"\nAdds two pieces of source code together, shifting the character-to-line mapping of the second piece as needed to maintain correct mapping.\n\nArgs:\n    self: The current SourceCode instance.\n    other: Another SourceCode instance to be concatenated after the current one.\n\nReturns:\n    SourceCode: A new SourceCode instance with the concatenated source strings and an appropriately adjusted character-to-line map.\n\"\"\"",
                    "method_name": "__add__",
                    "second_doc": "\"\"\"\nCombines two SourceCode instances by concatenating their source strings and merging their character-to-line mappings, ensuring line number consistency. This allows tracking of the origin of each character after joining multiple code fragments, which is important for subsequent analysis or visualization of code structure.\n\nArgs:\n    self (SourceCode): The current SourceCode instance.\n    other (SourceCode): Another SourceCode instance to append after the current one.\n\nReturns:\n    SourceCode: A new instance with concatenated source strings and a correctly adjusted character-to-line map.\n\"\"\"",
                    "source_code": "#If one operand is nothing, just return the value of this operand\n\t\tif not other:\n\t\t\treturn self.copy()\n\n\t\tif self.lastLineNumber()>other.firstLineNumber():\n\t\t\traise Exception(\"When adding two pieces of sourcecode, the second piece must be completely after the first as far as line numbers go\")\n\n\t\tsourceString = self.sourceString + other.sourceString\n\n\t\tshiftedCharacterToLineMap = {}\n\t\tcharacterPositions = other.characterToLineMap.keys()\n\t\tfor characterPosition in characterPositions:\n\t\t\tshiftedCharacterToLineMap[characterPosition+len(self.sourceString)] = other.characterToLineMap[characterPosition]\n\n\t\tcharacterToLineMap = dict(self.characterToLineMap.items() + shiftedCharacterToLineMap.items())\n\n\t\tret = SourceCode(sourceString=sourceString,characterToLineMap=characterToLineMap)\n\n\t\treturn ret"
                },
                {
                    "docstring": null,
                    "method_name": "__sub__",
                    "second_doc": "\"\"\"\nRemoves a specified segment of source code from the current source code object, effectively subtracting the content of another SourceCode instance that must be fully contained within the original. This enables manipulation and analysis of code fragments by precisely excluding known sub-regions.\n\nArgs:\n    other (SourceCode): The SourceCode instance representing the code segment to be removed. Must be wholly within the bounds of the current object.\n\nReturns:\n    SourceCode: A new SourceCode instance with the specified segment removed.\n\nRaises:\n    Exception: If the segment to be removed does not exist in the current source code or is not completely contained within it.\n\"\"\"",
                    "source_code": "if not other:\n\t\t\treturn self.copy()\n\n\t\tif self.firstLineNumber()>other.firstLineNumber() or self.lastLineNumber()<other.lastLineNumber():\n\t\t\tpdb.set_trace()\n\t\t\traise Exception(\"When subtracting a piece of one bit of sourcecode from another, the second must lie completely within the first\")\n\n\t\tfirstPos = self.sourceString.find(other.sourceString)\n\n\t\tif firstPos == -1:\n\t\t\tpdb.set_trace()\n\t\t\traise Exception('Could not subtract string starting with \"%s\" from source because string could not be found'%other.sourceString[:50].replace(\"\\n\",\"\\\\n\"))\n\n\t\tlastPos = firstPos + len(other.sourceString)\n\n\n\t\tfirstPart = self[:firstPos]\n\n\t\tsecondPart = self[lastPos:]\n\n\t\treturn firstPart+secondPart"
                },
                {
                    "docstring": "'''\n\t\t__nonzero__ is object evaluates to True or False\n\t\tsourceString will be False when the sourceString has nothing or nothing but whitespace\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns True if the object is considered non-empty.\n\nChecks whether the sourceString attribute contains any non-whitespace characters. The method evaluates the object in a boolean context.\n\nArgs:\n    self: The instance of the class for which the method is called.\n\nReturns:\n    bool: True if sourceString is not empty or does not contain only whitespace, otherwise False.\n\"\"\"",
                    "method_name": "__nonzero__",
                    "second_doc": "\"\"\"\nDetermines whether the sourceString attribute contains any meaningful content, ignoring whitespace. This helps identify if the associated object represents a valid or significant unit of code.\n\nArgs:\n    self: Instance of the SourceCode class.\n\nReturns:\n    bool: True if sourceString contains non-whitespace characters; False otherwise.\n\"\"\"",
                    "source_code": "return self.sourceString.strip()!=''"
                },
                {
                    "docstring": "'''\n\t\tMostly for debugging. Print the source with line numbers\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns a formatted string representation of the source with line numbers for debugging purposes.\n\nArgs:\n    self: The instance of the class.\n\nClass Fields Initialized in Constructor:\n    sourceString: Holds the source content as a string to be processed or displayed.\n    characterToLineMap: Maps character indices in the sourceString to their corresponding line numbers.\n\nReturns:\n    str: The source string with each line prepended by its corresponding line number.\n\"\"\"",
                    "method_name": "__str__",
                    "second_doc": "\"\"\"\nGenerates a string of the source text, where each line is prefixed with its line number, which aids in clearly associating source characters with their position for inspection or error tracing.\n\nArgs:\n    self: The current instance containing the source string and mapping from character indices to line numbers.\n\nReturns:\n    str: A string where each line of the source text is labeled with its corresponding line number, facilitating easier tracking and understanding of source code locations.\n\"\"\"",
                    "source_code": "ret = ''\n\t\tfor i, char in enumerate(self.sourceString):\n\t\t\tif i in self.characterToLineMap:\n\t\t\t\tret += '%d: '%self.characterToLineMap[i]\n\t\t\tret += char\n\t\treturn ret"
                },
                {
                    "docstring": null,
                    "method_name": "copy",
                    "second_doc": "\"\"\"\nCreates and returns a deep copy of the current SourceCode instance.\n\nThis allows the original object to remain unaltered while working with a separate, identical version, supporting operations that require modification or isolation of data without side effects.\n\nReturns:\n    SourceCode: A deep copy of the current SourceCode object.\n\"\"\"",
                    "source_code": "return copy.deepcopy(self)"
                },
                {
                    "docstring": "'''\n\t\tFirst line number of the entire source\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the first (smallest) line number present in the source code.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    int: The first line number found in the source code mapping.\n\nRaises:\n    Exception: If the source code has no associated line numbers.\n\"\"\"",
                    "method_name": "firstLineNumber",
                    "second_doc": "\"\"\"\nRetrieves the smallest line number from the source code's character-to-line mapping to identify the starting point of analyzed code.\n\nArgs:\n    self: Instance of SourceCode containing source mapping information.\n\nReturns:\n    int: The lowest line number detected in the character-to-line mapping.\n\nRaises:\n    Exception: If no line numbers are present in the mapping, indicating an absence of mappable source code content.\n\"\"\"",
                    "source_code": "try:\n\t\t\treturn min(self.characterToLineMap.values())\n\t\texcept ValueError:\n\t\t\traise Exception(\"Sourcecode has no line numbers\")"
                },
                {
                    "docstring": "'''\n\t\tLast line number of the entire source\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the last line number of the entire source code.\n\nRetrieves the highest line number from the character-to-line mapping for the source code. Raises an exception if no line numbers are available.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    int: The largest line number present in the source code.\n\nRaises:\n    Exception: If the source code has no line numbers.\n\"\"\"",
                    "method_name": "lastLineNumber",
                    "second_doc": "\"\"\"\nDetermines the highest line number used in the source code based on the character-to-line mapping, which is essential for tracking the location and span of code constructs. This helps in accurately mapping code elements to their positions within the original file.\n\nArgs:\n    self: The instance containing the character-to-line mapping for the source code.\n\nReturns:\n    int: The largest line number identified in the source code.\n\nRaises:\n    Exception: If the mapping is empty and no line numbers are available.\n\"\"\"",
                    "source_code": "try:\n\t\t\treturn max(self.characterToLineMap.values())\n\t\texcept ValueError:\n\t\t\traise Exception(\"Sourcecode has no line numbers\")"
                },
                {
                    "docstring": "'''\n\t\tRemove a string. Does not alter object in place\n\t\t'''",
                    "first_doc": "\"\"\"\nRemoves the first occurrence of a specified string from the source string without modifying the original object.\n\nArgs:\n    stringToRemove: The substring to be removed from the source string.\n\nReturns:\n    str: A new string with the specified substring removed from the source string. Raises an exception if the substring is not found.\n\"\"\"",
                    "method_name": "remove",
                    "second_doc": "\"\"\"\nRemoves the first occurrence of a specified substring from the source string and returns a new string, leaving the original object unchanged. This supports processes where precise string manipulation is required.\n\nArgs:\n    stringToRemove (str): The substring to be removed from the source string.\n\nReturns:\n    str: A new string with the specified substring removed. Raises an Exception if the substring is not found.\n\"\"\"",
                    "source_code": "firstPos = self.sourceString.find(stringToRemove)\n\t\tif firstPos == -1:\n\t\t\tpdb.set_trace()\n\t\t\traise Exception(\"String not found in source\")\n\t\tlastPos = firstPos + len(stringToRemove)\n\t\treturn self[:firstPos]+self[lastPos:]"
                },
                {
                    "docstring": "'''\n\t\tPop off the last line\n\t\t'''",
                    "first_doc": "\"\"\"\nRemoves and returns the last line from the source string.\n\nArgs:\n    self: The instance of the object this method is called on.\n\nReturns:\n    str: The last line from the source string, including the newline character.\n\"\"\"",
                    "method_name": "pop",
                    "second_doc": "\"\"\"\nExtracts and returns the last line from the source string, updating the source to exclude that line.\n\nThis method is used to progressively process and remove lines from the source, allowing for sequential parsing or analysis where handling one line at a time can simplify extraction of structural information or relationships.\n\nArgs:\n    self: Instance of the SourceCode class containing the source string.\n\nReturns:\n    str: The last line from the source string, including the newline character.\n\"\"\"",
                    "source_code": "lastLinePos = self.sourceString.rfind('\\n')\n\t\tret = self.sourceString[lastLinePos:]\n\t\tself = self[:lastLinePos]\n\n\t\treturn ret"
                },
                {
                    "docstring": "'''\n\t\tFrom lineNumber, get the character position\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the character position corresponding to a given line number.\n\nThis method searches for the first character position that maps to the specified line number within the internal character-to-line mapping.\n\nArgs:\n    lineNumberRequest: The line number for which to find the character position.\n\nReturns:\n    An integer representing the character position that marks the beginning of the specified line number.\n\nRaises:\n    Exception: If the specified line number is not found in the source.\n\"\"\"",
                    "method_name": "getPosition",
                    "second_doc": "\"\"\"\nFinds the starting character index of the specified line number using the internal mapping of character positions to line numbers.\n\nThis method is used to precisely locate a line's starting position in the source, facilitating accurate mapping and referencing within source code analysis tasks.\n\nArgs:\n    lineNumberRequest (int): The line number whose starting character position is to be retrieved.\n\nReturns:\n    int: The character position indicating where the requested line begins.\n\nRaises:\n    Exception: If the specified line number does not exist in the source.\n\"\"\"",
                    "source_code": "for pos,lineNumber in self.characterToLineMap.items():\n\t\t\tif lineNumber == lineNumberRequest:\n\t\t\t\treturn pos\n\n\t\traise Exception(\"Could not find line number in source\")"
                },
                {
                    "docstring": "'''\n\t\tDecrement until we find the first character of the line and can get the linenumber\n\t\t'''",
                    "first_doc": "\"\"\"\nFinds the line number corresponding to a given character position, decrementing the position if necessary until a valid entry is found.\n\nArgs:\n    self: The object instance.\n    pos: The character index for which to find the corresponding line number.\n\nReturns:\n    The line number associated with the given character position.\n\nRaises:\n    Exception: If the beginning of the input is reached without finding a valid line number.\n\"\"\"",
                    "method_name": "getLineNumber",
                    "second_doc": "\"\"\"\nAttempts to retrieve the line number for a specified character index by checking for a direct mapping and incrementally searching backward if necessary. This ensures that even if the exact character position is not mapped, the function can reliably determine its nearest preceding line number. This approach helps maintain accurate tracking of code structure during parsing and analysis.\n\nArgs:\n    pos (int): The character index within the source text for which the corresponding line number is required.\n\nReturns:\n    int: The line number that matches or precedes the given character position.\n\nRaises:\n    Exception: If no valid line number mapping exists for any character position at or before the specified index.\n\"\"\"",
                    "source_code": "while True:\n\t\t\ttry:\n\t\t\t\treturn self.characterToLineMap[pos]\n\t\t\texcept:\n\t\t\t\tpos-=1\n\t\t\t\tif pos < 0:\n\t\t\t\t\traise Exception(\"could not get line number for position %d\"%pos)"
                },
                {
                    "docstring": "'''\n\t\tPass through 'find' makes implementations cleaner\n\t\t'''",
                    "first_doc": "\"\"\"\nSearches for a substring within the source string.\n\nArgs:\n    what: The substring to search for within the source string.\n\nReturns:\n    int: The lowest index in the source string where the specified substring is found. Returns -1 if the substring is not found.\n\"\"\"",
                    "method_name": "find",
                    "second_doc": "\"\"\"\nLocates the starting index of a specified substring within the source code string to identify symbol or keyword positions, which assists in analyzing code structure.\n\nArgs:\n    what (str): The substring to search for within the source code.\n\nReturns:\n    int: The starting index of the substring if found, otherwise -1.\n\"\"\"",
                    "source_code": "return self.sourceString.find(what,start)"
                },
                {
                    "docstring": "'''\n\t\tReturn the source between the first pair of delimiters after 'startAt'\n\t\t'''",
                    "first_doc": "\"\"\"\nExtracts and returns the substring located between the first pair of specified delimiters found after a given starting position.\n\nArgs:\n    self: The instance of the object containing the required attributes:\n        sourceString: The source text to search within.\n        delimA: The starting delimiter.\n        delimB: The ending delimiter.\n        delimLen: The length of the starting delimiter.\n        endDelimPos: A method for finding the position of the ending delimiter.\n\nReturns:\n    str or None: The substring found between the specified delimiters, or None if no such substring exists.\n\"\"\"",
                    "method_name": "extractBetweenDelimiters",
                    "second_doc": "\"\"\"\nFinds and returns a substring enclosed between the first occurrence of given delimiters, starting from a specific position in the source text. This facilitates the identification and extraction of meaningful code units or expressions within larger code sequences.\n\nArgs:\n    startAt (int): The index in the source string from which to begin searching for the starting delimiter.\n\nReturns:\n    str or None: The text located between the first matching pair of delimiters after the given position, or None if no valid substring is found.\n\"\"\"",
                    "source_code": "start = self.sourceString.find(self.delimA,startAt)\n\t\tif start == -1:\n\t\t\treturn None\n\t\tstart += self.delimLen\n\n\t\tendPos = self.endDelimPos(start,self.delimA,self.delimB)\n\t\tif endPos != -1:\n\t\t\treturn self[start:endPos]\n\t\telse:\n\t\t\treturn None"
                },
                {
                    "docstring": "'''\n\t\tGet the source within two matching brackets\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the source code located between two matching brackets, given the position of one bracket.\n\nArgs:\n    self: The object instance.\n    bracketPos: The position of one of the matching brackets in the source.\n\nReturns:\n    The substring of the source found between the two matching brackets, excluding the brackets themselves.\n\"\"\"",
                    "method_name": "getSourceInBlock",
                    "second_doc": "\"\"\"\nExtracts and returns the source code that lies between a pair of matching brackets, given the position of one bracket. This facilitates accurate parsing and structural analysis of code blocks by isolating their internal contents.\n\nArgs:\n    bracketPos (int): The index of one of the matching brackets in the source code.\n\nReturns:\n    str: The substring located between the two matching brackets, not including the brackets themselves.\n\"\"\"",
                    "source_code": "otherBracketPosition = self.matchingBracketPos(bracketPos)\n\n\t\tif bracketPos < otherBracketPosition:\n\t\t\tstartBracketPos = bracketPos\n\t\t\tendBracketPos = otherBracketPosition\n\t\telse:\n\t\t\tstartBracketPos = otherBracketPosition\n\t\t\tendBracketPos = bracketPos\n\n\t\tret = self[startBracketPos+1:endBracketPos]\n\t\treturn ret"
                },
                {
                    "docstring": "'''\n\t\tFind the matching bracket position\n\t\t'''",
                    "first_doc": "\"\"\"\nFinds the position of the bracket that matches the bracket at the specified position.\n\nArgs:\n    bracketPos: The position in the string to check for the matching bracket.\n\nReturns:\n    int: The position of the matching bracket in the source string.\n\nRaises:\n    Exception: If the character at the given position is not a known delimiter.\n\"\"\"",
                    "method_name": "matchingBracketPos",
                    "second_doc": "\"\"\"\nDetermines the index of the bracket that correctly pairs with the bracket at the specified position, allowing for accurate navigation or parsing of delimited sections within the source string.\n\nArgs:\n    bracketPos (int): The index in the string to find the corresponding matching bracket for.\n\nReturns:\n    int: The index of the bracket that forms a valid pair with the bracket at the given position.\n\nRaises:\n    Exception: If the character at the provided index is not a recognized bracket delimiter.\n\"\"\"",
                    "source_code": "delim = self[bracketPos]\n\t\tif delim == self.delimA:\n\t\t\tif self.sourceString[bracketPos+1]==self.delimB:\n\t\t\t\treturn bracketPos + 1\n\t\t\telse:\n\t\t\t\treturn self.endDelimPos(startAt=bracketPos+1)\n\t\telif delim == self.delimB:\n\t\t\tif self.sourceString[bracketPos-1]==self.delimA:\n\t\t\t\treturn bracketPos - 1\n\t\t\telse:\n\t\t\t\treturn self.openDelimPos(startAt=bracketPos-1)\n\t\telse:\n\t\t\traise Exception('\"%s\" is not a known delimiter'%delim)"
                },
                {
                    "docstring": "'''\n\t\tFind the nearest end delimiter assuming that 'startAt' is inside of a block\n\t\t'''",
                    "first_doc": "\"\"\"\nFinds the position of the nearest end delimiter in the source string, starting from a specified index inside a block.\n\nArgs:\n    startAt: The index in the source string where the search should begin. It is assumed that this position is inside a block delimited by matching delimiters.\n\nReturns:\n    int: The index of the nearest end delimiter matching the block structure, or -1 if no matching end delimiter is found.\n\nClass Fields Initialized:\n    self.sourceString: The source string in which delimiter positions are searched.\n    self.delimLen: The length of the delimiter strings.\n    self.delimA: The start delimiter string.\n    self.delimB: The end delimiter string.\n\"\"\"",
                    "method_name": "endDelimPos",
                    "second_doc": "\"\"\"\nScans the source string starting from a given index to locate the position of the corresponding end delimiter that closes the current block, properly accounting for nested structures.\n\nArgs:\n    startAt (int): The index within the source string to begin the search; assumed to be inside a delimited block.\n\nReturns:\n    int: The index of the matching end delimiter that closes the current block, or -1 if no such delimiter is found.\n\nWhy:\n    This method is used to accurately delineate code blocks based on matching delimiters, which is essential for reliably identifying function and control flow boundaries within the source code during parsing.\n\"\"\"",
                    "source_code": "count = 1\n\t\ti = startAt\n\t\twhile i<len(self.sourceString) and count>0:\n\t\t\ttmp = self.sourceString[i:i+self.delimLen]\n\t\t\tif tmp==self.delimA:\n\t\t\t\tcount += 1\n\t\t\t\ti+=self.delimLen\n\t\t\telif tmp==self.delimB:\n\t\t\t\tcount -= 1\n\t\t\t\ti+=self.delimLen\n\t\t\telse:\n\t\t\t\ti+=1\n\n\t\tif count == 0:\n\t\t\treturn i-self.delimLen\n\t\telse:\n\t\t\treturn -1"
                },
                {
                    "docstring": "'''\n\t\tFind the nearest begin delimiter assuming that 'pos' is inside of a block\n\t\tTODO there is probably no reason why this also includes parenthesis\n\t\tTODO this should probably just be the same function as endDelimPos\n\t\t'''",
                    "first_doc": "\"\"\"\nFinds the nearest opening delimiter position in the source string before or at the given position.\n\nThis method searches backward from the specified position to locate the matching opening delimiter ('{' or '(') corresponding to a closing delimiter ('}' or ')'), under the assumption that the starting position is inside a block.\n\nArgs:\n    pos: The index position in the source string from which to start searching backward for the opening delimiter.\n\nReturns:\n    int: The index of the nearest opening delimiter; returns 0 if no matching opening delimiter is found.\n\"\"\"",
                    "method_name": "openDelimPos",
                    "second_doc": "\"\"\"\nIdentifies the position of the nearest unmatched opening block or parenthesis before or at a given index in the source string, by traversing backwards and balancing delimiters.\n\nThis process helps accurately determine code block boundaries, which is essential for correctly interpreting nesting and function scopes within the source code.\n\nArgs:\n    pos (int): The index in the source string to begin the backward search for an opening delimiter.\n\nReturns:\n    int: The index of the nearest unmatched opening '{' or '(' delimiter, or 0 if none is found.\n\"\"\"",
                    "source_code": "count = 0\n\t\ti = pos\n\t\twhile i>=0 and count>=0:\n\t\t\tif self.sourceString[i] in ('}',')'):\n\t\t\t\tcount += 1\n\t\t\telif self.sourceString[i] in ('{','('):\n\t\t\t\tcount -= 1\n\t\t\ti-=1\n\n\t\tif count==-1:\n\t\t\treturn i+1\n\t\telse:\n\t\t\treturn 0"
                },
                {
                    "docstring": "'''\n\n\t\tTwo things happen here:\n\t\ta. Character by character, add those characters which are not part of comments or strings to a new string\n\t\t   Same the new string as the 'sourceString' variable\n\t\tb. At the same time, generate an array of line number beginnings called the 'characterToLineMap'\n\n\t\tThis uses a mutable string to save time on adding\n\n\t\t'''",
                    "first_doc": "\"\"\"\nRemoves comments and string literals from the source code, updating the source string and tracking line numbers.\n\nThis method processes the original source code, character by character, to create a new version of the code with all comments and string literals removed. Simultaneously, it generates a mapping from character positions to source line numbers to maintain accurate position information. The method is useful for preparing source code for further analysis or processing while ignoring commented or string content.\n\nArgs:\n    self: Instance of the class. Uses and updates several object properties.\n\nReturns:\n    None: This method modifies the following instance attributes:\n        - sourceString: Updated to contain the source code with comments and strings removed.\n        - characterToLineMap: A dictionary mapping character positions in the cleaned source string to their corresponding source line numbers.\n\"\"\"",
                    "method_name": "_removeCommentsAndStrings",
                    "second_doc": "\"\"\"\nSanitizes the source code by stripping out comments and string literals, while maintaining an accurate mapping between cleaned code character positions and their original source line numbers.\n\nThis process enables precise tracking of code structure without interference from non-executable elements such as comments, ensuring subsequent parsing and analysis focus solely on operational code elements.\n\nArgs:\n    self: The instance of the SourceCode class. Relies on and updates its sourceString, inlineComments, blockComments, and characterToLineMap attributes.\n\nReturns:\n    None: The method modifies these instance attributes:\n        - sourceString: Rewritten to contain the code with comments and string literals removed.\n        - characterToLineMap: Updated to map positions in the sanitized sourceString to their corresponding original source line numbers.\n\"\"\"",
                    "source_code": "print \"Removing comments and strings...\"\n\n\t\toriginalString = str(self.sourceString)\n\t\tself.sourceString = MString('')\n\t\tself.characterToLineMap = {}\n\t\tlineCount = 1\n\t\tself.characterToLineMap[0] = lineCount #character 0 is line #1\n\t\tlineCount += 1 #set up for next line which will be two\n\t\t#pdb.set_trace()\n\t\ti=0\n\n\t\tinlineCommentLen = len(self.inlineComments)\n\n\t\t#begin analyzing charactes 1 by 1 until we reach the end of the originalString\n\t\t#-blockCommentLen so that we don't go out of bounds\n\t\twhile i < len(originalString):\n\t\t\t#check if the next characters are a block comment\n\t\t\t#There are multiple types of block comments so we have to check them all\n\t\t\tfor blockComment in self.blockComments:\n\t\t\t\tif type(blockComment['start']) == str:\n\t\t\t\t\tblockCommentLen = len(blockComment['start'])\n\t\t\t\t\tif originalString[i:][:blockCommentLen] == blockComment['start']:\n\t\t\t\t\t\t#if it was a block comment, jog forward\n\t\t\t\t\t\tprevI = i\n\t\t\t\t\t\ti = originalString.find(blockComment['end'],i+blockCommentLen)+blockCommentLen\n\n\t\t\t\t\t\twhile originalString[i-1]=='\\\\':\n\t\t\t\t\t\t\ti = originalString.find(blockComment['end'],i+blockCommentLen)+blockCommentLen\n\n\t\t\t\t\t\tif i==-1+blockCommentLen:\n\t\t\t\t\t\t\t#if we can't find the blockcomment and have reached the end of the file\n\t\t\t\t\t\t\t#return the cleaned file\n\t\t\t\t\t\t\treturn\n\n\t\t\t\t\t\t#increment the newlines\n\t\t\t\t\t\tlineCount+=originalString[prevI:i].count('\\n')\n\n\t\t\t\t\t\t#still want to see the comments, just not what is inside\n\t\t\t\t\t\tself.sourceString.append(blockComment['start'] + blockComment['end'])\n\n\t\t\t\t\t\tbreak\n\t\t\t\telse:\n\t\t\t\t\t#is a regex blockcomment... sigh js sigh...\n\t\t\t\t\tmatch = blockComment['start'].match(originalString[i:])\n\t\t\t\t\tif match:\n\t\t\t\t\t\t#print match.group(0)\n\t\t\t\t\t\t#print originalString[i-5:i+5]\n\t\t\t\t\t\tprevI = i\n\n\t\t\t\t\t\tendMatch = blockComment['end'].search(originalString[i+match.end(0):])\n\n\t\t\t\t\t\tif endMatch:\n\t\t\t\t\t\t\ti = i+match.end(0)+endMatch.end(0)\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\treturn\n\n\t\t\t\t\t\t#increment the newlines\n\t\t\t\t\t\tlineCount+=originalString[prevI:i].count('\\n')\n\t\t\t\t\t\tbreak\n\t\t\telse:\n\t\t\t\t#check if the next characters are an inline comment\n\t\t\t\tif originalString[i:][:inlineCommentLen] == self.inlineComments:\n\t\t\t\t\t#if so, find the end of the line and jog forward. Add one to jog past the newline\n\t\t\t\t\ti = originalString.find(\"\\n\",i+inlineCommentLen+1)\n\n\t\t\t\t\t#if we didn't find the end of the line, that is the end of the file. Return\n\t\t\t\t\tif i==-1:\n\t\t\t\t\t\treturn\n\t\t\t\telse:\n\t\t\t\t\t#Otherwise, it is not a comment. Add to returnstr\n\t\t\t\t\tself.sourceString.append(originalString[i])\n\n\t\t\t\t\t#if the originalString is a newline, then we must note this\n\t\t\t\t\tif originalString[i]=='\\n':\n\t\t\t\t\t\tself.characterToLineMap[len(self.sourceString)] = lineCount\n\t\t\t\t\t\tlineCount += 1\n\t\t\t\t\ti+=1"
                }
            ],
            "name": "SourceCode",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": "'''\n\t\tTwo things are happening:\n\t\t1. We are overwriting all of the classes with the implementation's classes\n\t\t\tSo if we are working with a javascript file, the implementation variable points to javascript.py\n\t\t\tThen, we overwrite every class in engine.py with all of the javascript.py's classes\n\t\t2. We are loading the source files into the mapper class\n\t\t'''",
                    "first_doc": "\"\"\"\nInitializes the class by replacing engine classes with those from the provided implementation and loading the content of source files.\n\nArgs:\n    implementation: The module containing alternative class definitions to replace the engine's core classes.\n    files: A list of paths to source code files that will be read and loaded.\n\nAttributes:\n    files: A dictionary mapping file paths to their corresponding file content, used to store and manage loaded source files.\n\nReturns:\n    None: This constructor does not return a value.\n\"\"\"",
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes the class by dynamically assigning core classes from an external module and loading the contents of provided source code files into memory.\n\nThis approach allows the system to flexibly adapt its behavior and analysis depending on which class implementations are supplied, and to prepare the source code data for further processing and analysis.\n\nArgs:\n    implementation: A module providing alternate definitions for the core classes to be used for processing and analysis.\n    files: A list of file paths to source code files to be loaded.\n\nAttributes:\n    files: A dictionary storing the content of each loaded source file, keyed by file path.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "global Node,Edge,Group,Mapper,SourceCode\n\t\tNode = implementation.Node\n\t\tEdge = implementation.Edge\n\t\tGroup = implementation.Group\n\t\tMapper = implementation.Mapper\n\t\tSourceCode = implementation.SourceCode\n\n\t\tfor f in files:\n\t\t\twith open(f) as fi:\n\t\t\t\tself.files[f] = fi.read()"
                },
                {
                    "docstring": "'''\n\t\tI. For each file passed,\n\t\t\t1. Generate the sourcecode for that file\n\t\t\t2. Generate a group from that file's sourcecode\n\t\t\t\ta. The group init will recursively generate all of the subgroups and function nodes for that file\n\t\tII.  Trim the groups bascially removing those which have no function nodes\n\t\tIII. Generate the edges\n\t\tIV.  Return the file groups, function nodes, and edges\n\t\t'''",
                    "first_doc": "\"\"\"\nProcesses the files associated with the object to generate function nodes, group them by file, trim unnecessary structure, and determine the edges representing relationships between the functions.\n\nFor each file, the method extracts its source code, generates a structured group of its functions and classes, trims groups without function nodes, and identifies connections (edges) between function nodes. Returns the organized groups, a list of function nodes, and the edges.\n\nParameters:\n  self: The instance of the class. This method uses self.files (a mapping of filenames to contents) and calls other instance methods.\n\nClass Fields Initialized:\n  None. (This method does not initialize any class fields; it operates on self.files and other instance data.)\n\nReturns:\n  tuple: A tuple containing:\n    - fileGroups: List of group objects, each representing the structure for a file (with sub-groups and function nodes).\n    - finalNodes: List of function node objects that are meaningful (extraneous/global nodes are removed).\n    - edges: The computed edges representing connections between function nodes.\n\"\"\"",
                    "method_name": "map",
                    "second_doc": "\"\"\"\nAnalyzes the files associated with the object to extract functions, group them by file and class, remove irrelevant or empty groups, and identify relationships between the functions in the form of edges.\n\nThis method systematically organizes code elements, cleans up unneeded structures, and determines interconnections between significant functions to facilitate a higher-level structural understanding.\n\nArgs:\n  self: An instance of the Mapper class, utilizing its files attribute (a dictionary mapping filenames to their content) and instance methods to process the source code.\n\nReturns:\n  tuple:\n    - fileGroups (list): A list of structured group objects for each file, detailing contained functions and classes.\n    - finalNodes (list): A list of function node objects deemed meaningful after filtering out non-essential (extraneous) functions.\n    - edges (list): Relationships between meaningful function nodes, indicating how functions are interconnected.\n\nWhy:\n  The method performs this processing to distill complex codebases into organized, meaningful components and their relationships, enabling clear analysis and visualization of functional structure and interdependencies.\n\"\"\"",
                    "source_code": "#get the filename and the fileString\n\t\t#only first file for now\n\t\tnodes = []\n\t\tfileGroups = []\n\t\tfor filename,fileString in self.files.items():\n\t\t\t#remove .py from filename\n\t\t\tfilename = self.simpleFilename(filename)\n\t\t\tprint \"Mapping %s\"%filename\n\n\t\t\t#generate sourcecode (remove comments and add line numbers)\n\t\t\tsource = SourceCode(fileString)\n\n\t\t\t#Create all of the subgroups (classes) and nodes (functions) for this file\n\t\t\tprint \"Generating function nodes...\"\n\t\t\tfileGroup = self.generateFileGroup(name=filename,source=source)\n\t\t\tfileGroups.append(fileGroup)\n\n\t\t\t#Append nodes generated to all nodes\n\t\t\tnodes += fileGroup._allNodes()\n\n\t\t#Trimming the groups mostly removes those groups with no function nodes\n\t\tfor group in fileGroups:\n\t\t\tgroup.trimGroups()\n\t\t\tif DEBUG:\n\t\t\t\tprint \"Post trim, %s\"%group.name\n\t\t\t\tgroup._pprint()\n\n\t\t#Figure out what functions map to what\n\t\tprint \"Generating edges...\"\n\t\tedges = generateEdges(nodes)\n\n\t\t#Trim off the nodes (mostly global-frame nodes that don't do anything)\n\t\tfinalNodes = []\n\t\tfor node in nodes:\n\t\t\tif not node.isExtraneous(edges):\n\t\t\t\tfinalNodes.append(node)\n\t\t\telse:\n\t\t\t\tnode.parent.nodes.remove(node)\n\t\t\t\tdel node\n\n\n\t\t#return everything we have done\n\t\treturn fileGroups,finalNodes,edges"
                },
                {
                    "docstring": "'''\n\t\tDummy function probably superclassed\n\t\tThis will initialize the global group for the entire source file\n\t\t'''",
                    "first_doc": "\"\"\"\nInitializes and returns the global group for the entire source file.\n\nArgs:\n    name: The name to assign to the global group.\n    source: The source file or source information associated with the group.\n\nReturns:\n    Group: A Group object representing the global group for the source file.\n\"\"\"",
                    "method_name": "generateFileGroup",
                    "second_doc": "\"\"\"\nCreates and returns a Group object that encapsulates all code elements at the file level.\n\nThis groups all global definitions together, providing a structured root node that reflects the overall organization of the source file content. This grouping is essential for building a hierarchical representation that accurately captures the relationships within the file for further analysis and visualization.\n\nArgs:\n    name (str): The identifier for the global group.\n    source (Any): The source file or related metadata to associate with this group.\n\nReturns:\n    Group: An instance representing the top-level code grouping for the analyzed file.\n\"\"\"",
                    "source_code": "return Group(name=name,source=source)"
                },
                {
                    "docstring": "'''\n\t\tReturn the filename without the path\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the filename without its extension or path.\n\nThis method removes the file extension from the provided filename string, if present.\n\nArgs:\n    filename: The complete filename (with or without extension) from which to extract the simple filename.\n\nReturns:\n    str: The filename string without its extension or path.\n\"\"\"",
                    "method_name": "simpleFilename",
                    "second_doc": "\"\"\"\nExtracts and returns the file's base name by removing its extension and any path information.\n\nThis method isolates the core, extension-free filename from a provided full filename string to ensure consistency and clarity when referencing files, making downstream file identification and display more straightforward.\n\nArgs:\n    filename (str): The complete filename, potentially including both directory path and file extension.\n\nReturns:\n    str: The base filename, stripped of both extension and any leading path.\n\"\"\"",
                    "source_code": "if '.' in filename:\n\t\t\tfilename = filename[:filename.rfind('.')]\n\n\t\treturn filename"
                }
            ],
            "name": "Mapper",
            "type": "class"
        }
    ],
    "code2flow/code2flowlib/languages/__init__.py": [],
    "code2flow/code2flowlib/languages/javascript.py": [
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "linksTo",
                    "second_doc": "\"\"\"\nDetermines whether the current node can be linked to another node based on shared parent scope or matching namespace patterns.\n\nArgs:\n    other (Node): The node to which a potential link is being evaluated.\n\nReturns:\n    bool: True if the nodes should be linked due to scope or namespace patterns; False otherwise.\n\nThis method evaluates linking to represent relationships and potential interactions between nodes, facilitating an accurate mapping of code structure.\n\"\"\"",
                    "source_code": "if other.parent == self.parent:\n\t\t\tif any(map(lambda pattern: pattern.search(self.source.sourceString), other.sameScopePatterns)):\n\t\t\t\treturn True\n\n\t\t#if other.name == 'c':\n\t\t#\tpdb.set_trace()\n\n\t\t#Otherwise, they can always be linked by a shared namespace\n\t\t#must generate namespace here because we are trimming the groups AFTER init of the node\n\t\tif any(map(lambda pattern: pattern.search(self.source.sourceString), other.generateAnyScopePatterns())):\n\t\t\treturn True\n\n\t\treturn False"
                },
                {
                    "docstring": null,
                    "method_name": "getNamespace",
                    "second_doc": "\"\"\"\nTraverses up the node hierarchy to retrieve the namespace associated with the current node. If the current node shares a name with its parent, it skips an additional level up to avoid namespace ambiguity.\n\nArgs:\n    self: The instance of the Node for which the namespace is being determined.\n\nReturns:\n    The namespace string value obtained from the appropriate ancestor node.\n\"\"\"",
                    "source_code": "if self.parent.name != self.name:\n\t\t\treturn self.parent.getNamespace()\n\t\telse:\n\t\t\treturn self.parent.parent.getNamespace()"
                },
                {
                    "docstring": "'''\n\t\tHow you would call this node from any scope\n\t\t'''",
                    "first_doc": "\"\"\"\nGenerates a list of regex patterns to match calls to this node from any scope.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    list: A list of compiled regular expression patterns for detecting calls to this node from any scope.\n\"\"\"",
                    "method_name": "generateAnyScopePatterns",
                    "second_doc": "\"\"\"\nBuilds a comprehensive list of regex patterns to identify function calls to this node, including those made via the window object in JavaScript code. This allows for accurate detection of various invocation styles, ensuring that all relevant call relationships can be captured during code analysis.\n\nArgs:\n    self: Instance of the Node class representing a function or code element.\n\nReturns:\n    list: Compiled regex patterns to match calls to this node from any location, including specific patterns for JavaScript window object references.\n\"\"\"",
                    "source_code": "return super(Node,self).generateAnyScopePatterns()+[\n\t\t\tre.compile(r\"(?:[^a-zA-Z0-9\\.]|\\A)window\\.%s\\s*\\(\"%(self.getFullName()),re.MULTILINE|re.DOTALL)\n\t\t\t]"
                }
            ],
            "name": "Node",
            "type": "class"
        },
        {
            "methods": [],
            "name": "Edge",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": "'''\n\t\tGenerate a new group\n\n\t\tIteratively find blocks (objects and functions delimited by brackets) within this group and generate subgroups from them\n\t\tIf this is a functional group (can call functions and is not a simple array)\n\t\t, remove the subgroups found from the sourcecode and use those to generate the implicit node\n\n\t\tisFunction means the group is a regular function and has an implicit node\n\t\tnot isFunction would mean the group is an object meant for grouping like a = {b=function,c=function}\n\n\t\tisAnon means the function has no name and is not likely to be called outside of this scope\n\t\t'''",
                    "first_doc": "\"\"\"\nInitializes a new group, parsing its source code to identify and generate subgroups for code blocks delimited by brackets.\n\nThis constructor scans the group's source for objects and functions defined within brackets, recursively creating subgroups for each detected block. For functional groups, subgroups are removed from the source and are used to generate an implicit node. The behavior varies based on whether the group represents a regular function or an object purely for grouping.\n\nArgs:\n    isAnon: Indicates whether the function is anonymous and unlikely to be called outside of its current scope.\n\nAttributes:\n    isAnon: Indicates whether the function is anonymous and unlikely to be called outside of its current scope.\n    nodes: Stores nodes (such as implicit function nodes) belonging to this group.\n    subgroups: Holds subgroups (child groups) contained within this group.\n    parent: Reference to the parent group (if any).\n\nReturns:\n    None. This is a class constructor and does not return a value.\n\"\"\"",
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nParses the group's source code to identify code blocks delimited by brackets, organizes them into hierarchical subgroups, and prepares nodes that represent the logical structure of the source.\n\nThis method systematically analyzes structured code blocks for clear organization, enabling the extraction and grouping of nested elements. For groups representing functions, it removes detected subgroups from the source and creates implicit nodes to accurately reflect their composition. The handling of groups ensures hierarchical relationships are maintained according to code structure and scope.\n\nArgs:\n    isAnon (bool): True if the group represents an anonymous function unlikely to be referenced outside its current context.\n\nReturns:\n    None. This is a class constructor and does not return a value.\n\nWhy:\n    By recursively identifying and organizing code blocks into subgroups and nodes, this method enables precise modeling of source structure, supporting detailed analysis and subsequent visualization of logical dependencies within the codebase.\n\"\"\"",
                    "source_code": "super(Group,self).__init__(**kwargs)\n\t\tself.isAnon = isAnon\n\n\t\tblocksToRemove = []\n\n\t\topenBracket = self.source.find('{')\n\n\t\twhile openBracket != -1:\n\t\t\t'''\n\t\t\tWhile we do have a \"next function/object\" to handle:\n\t\t\t* find the close bracket for this block\n\t\t\t* extract the source of the block and the source immediately prior to this block\n\t\t\t* generate a group from this source and the prior source\n\t\t\t* if we managed to create a group, see below\n\t\t\t'''\n\n\t\t\tcloseBracket = self.source.matchingBracketPos(openBracket)\n\t\t\tif closeBracket == -1:\n\t\t\t\tprint \"Could not find closing bracket for open bracket on line %d in file %s\"%(self.source.getLineNumber(openBracket),self.name)\n\t\t\t\tprint \"You might have a syntax error. Setting closing bracket position to EOF\"\n\t\t\t\tcloseBracket = len(self.source)\n\n\t\t\t#Try generating a new group\n\t\t\t#This will fail if it is a function pattern we do not understand\n\t\t\tnewGroup = self.newGroupFromBlock(openBracket,closeBracket)\n\n\t\t\tif newGroup:\n\t\t\t\t'''\n\t\t\t\tAppend this new group to the proper namespace\n\n\t\t\t\tEither\n\t\t\t\tA. The new group was not anonymous, and contained more than an implicit node\n\t\t\t\tB. The new group was anonymous but had subgroups in which case we want those subgroups to be our subgroups\n\n\t\t\t\tEither way:\n\t\t\t\t1. push the newly created group to it's parent  which is probably us unless something like MainMap.blah = function happened\n\t\t\t\t2. append this group to the groups we will later have to remove when generating the implicit node\n\t\t\t\t'''\n\n\t\t\t\tif not (newGroup.isAnon and len(newGroup.nodes)==1 and newGroup.nodes[0].name==newGroup.name):\n\t\t\t\t\t\tnewGroup.parent.subgroups.append(newGroup)\n\t\t\t\t\t\tblocksToRemove.append(newGroup)\n\t\t\t\telif newGroup.subgroups:\n\t\t\t\t\tfor group in newGroup.subgroups:\n\t\t\t\t\t\tif group.parent == newGroup:\n\t\t\t\t\t\t\tgroup.parent = self\n\t\t\t\t\t\tgroup.parent.subgroups.append(group)\n\t\t\t\t\tblocksToRemove.append(newGroup)\n\n\t\t\t#get the next block to handle\n\t\t\topenBracket = self.source.find('{',closeBracket)\n\n\t\tif isFunction:\n\t\t\tnewNode = self.generateImplicitNode(blocksToRemove)\n\t\t\tself.nodes.append(newNode)"
                },
                {
                    "docstring": "'''\n\t\tReturns the full string namespace of this group including this group's name\n\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the full string namespace of this group, including this group's name.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    str: The full namespace as a string, constructed by joining the parent group's namespace with this group's name. Returns an empty string if there is no parent.\n\"\"\"",
                    "method_name": "getNamespace",
                    "second_doc": "\"\"\"\nConstructs and returns the hierarchical namespace for this group instance by recursively combining its name with the namespaces of its parents.\n\nArgs:\n    self: Instance of the Group class for which the namespace is being determined.\n\nReturns:\n    str: A dot-separated string representing the full namespace path from the root parent to this group. Returns an empty string if the group has no parent.\n\nWhy:\n    This method ensures that every group can be uniquely identified within a potentially nested or modular structure by tracing its lineage, which aids in accurate referencing and disambiguation within larger systems or visual representations.\n\"\"\"",
                    "source_code": "if not self.parent:\n\t\t\treturn ''\n\t\telse:\n\t\t\tret = self.name\n\t\t\tif self.parent.getNamespace():\n\t\t\t\tret = self.parent.getNamespace() + '.' + ret\n\t\t\treturn ret"
                },
                {
                    "docstring": "'''\n\t\tIf a group has only the implicit node, make that into a node and trim it\n\t\t'''",
                    "first_doc": "\"\"\"\nTrims subgroups by collapsing groups with only an implicit node and cleans up the subgroup list.\n\nIterates over the subgroups and, for each group, trims its nested groups recursively. If a group contains only a single node that has the same name as the group, the node is promoted to the current group's node list, and the group is removed from the subgroups.\n\nArgs:\n    self: The instance of the class on which this method is called. Must have 'subgroups' and 'nodes' attributes.\n\nReturns:\n    None: This method modifies the object's subgroups and nodes in place and does not return a value.\n\"\"\"",
                    "method_name": "trimGroups",
                    "second_doc": "\"\"\"\nSimplifies the group hierarchy by removing redundant subgroup layers and integrating orphan nodes into their parent group.\n\nThis method traverses all nested subgroups, recursively trimming away groups that do not contribute meaningful structural information\u2014specifically, those that contain only a single node with the same name as the group. Such nodes are elevated to the parent group's node list, and the empty subgroup is discarded. This process ensures the group's structure remains concise and easier to interpret by eliminating unnecessary nesting.\n\nArgs:\n    self: The Group instance on which this method operates. The object must contain 'subgroups' (list of Group instances) and 'nodes' (list of node objects).\n\nReturns:\n    None: All modifications are performed in place; no value is returned.\n\"\"\"",
                    "source_code": "savedSubgroups = []\n\n\t\tfor group in self.subgroups:\n\t\t\tgroup.trimGroups()\n\t\t\tif not group.subgroups:\n\t\t\t\tif not group.nodes:\n\t\t\t\t\tcontinue\n\t\t\t\tif len(group.nodes)==1 and group.nodes[0].name == group.name:\n\t\t\t\t\tgroup.nodes[0].parent = self\n\t\t\t\t\tself.nodes.append(group.nodes[0])\n\t\t\t\t\tcontinue\n\t\t\tsavedSubgroups.append(group)\n\t\tself.subgroups = savedSubgroups"
                },
                {
                    "docstring": null,
                    "method_name": "generateNewObjectPattern",
                    "second_doc": "\"\"\"\nGenerates and returns a compiled regular expression pattern for matching instances where a new object of this group's type is created in the code. This enables the identification of object instantiations during code analysis, which is essential for accurately mapping relationships and constructing call graphs.\n\nArgs:\n    None\n\nReturns:\n    re.Pattern: A compiled regex pattern that matches 'new <name>(' expressions, where '<name>' is the group's name.\n\"\"\"",
                    "source_code": "return re.compile(r'new\\s+%s\\s*\\('%self.name)"
                },
                {
                    "docstring": null,
                    "method_name": "generateNewObjectAssignedPattern",
                    "second_doc": "\"\"\"\nGenerates a compiled regular expression pattern to match assignments where an object is instantiated from the current class by name.\n\nArgs:\n    None\n\nReturns:\n    re.Pattern: A regular expression object that matches lines where a single-character variable is assigned a new instance of the class, e.g., `x = new ClassName(`.\n\nWhy:\n    This method constructs a pattern to identify object instantiations in source code, facilitating the extraction of relationships and dependencies necessary for accurate code structure analysis.\n\"\"\"",
                    "source_code": "return re.compile(r'(\\w)\\s*=\\s*new\\s+%s\\s*\\('%self.name)"
                },
                {
                    "docstring": null,
                    "method_name": "generateNamespaces",
                    "second_doc": "\"\"\"\nGenerates and returns a list of namespace identifiers used for grouping and referencing code elements. This method ensures consistent namespace formats for both direct and window-based references, which supports organized code analysis and later visualization.\n\nArgs:\n    None\n\nReturns:\n    list: A list containing the local namespace string and its equivalent in the \"window\" scope, or \"window\" alone if no namespace is defined.\n\"\"\"",
                    "source_code": "return [\n\t\t\tself.getNamespace()\n\t\t\t,'window.'+self.getNamespace() if self.getNamespace() else 'window'\n\t\t\t]"
                },
                {
                    "docstring": null,
                    "method_name": "findNamespace",
                    "second_doc": "\"\"\"\nSearches for a group containing the specified namespace, traversing through subgroups and parent groups as needed to locate it while avoiding cycles.\n\nArgs:\n    namespace (str): The namespace identifier to look for.\n    callingGroup (Group): The group that initiated the current search, used to prevent revisiting the same group in recursion.\n\nReturns:\n    Group or bool: Returns the Group instance that matches the namespace if found; otherwise, returns False.\n\nWhy:\n    This method helps accurately trace ownership and relationships of namespaces throughout nested and hierarchical group structures, which is essential for identifying how functions and components are organized and interact within the codebase.\n\"\"\"",
                    "source_code": "if any(map(lambda thisNamespace: thisNamespace==namespace, self.generateNamespaces())):\n\t\t\treturn self\n\t\telse:\n\t\t\tfor group in self.subgroups:\n\t\t\t\tif group!=callingGroup and group.findNamespace(namespace=namespace,callingGroup=self):\n\t\t\t\t\treturn group\n\t\t\tif self.parent and self.parent != callingGroup:\n\t\t\t\treturn self.parent.findNamespace(namespace=namespace,callingGroup=self)\n\t\t\telse:\n\t\t\t\treturn False"
                },
                {
                    "docstring": null,
                    "method_name": "generateImplicitNode",
                    "second_doc": "\"\"\"\nGenerates an implicit Node instance representing this group with specified code blocks removed from its source.\n\nThis method prepares a new node by copying the group's source, excluding sections corresponding to blocksToRemove. It distinguishes whether the node represents the root of a file, assigning an appropriate name and flag. The resulting Node encapsulates the updated code structure, facilitating further analysis or visualization.\n\nArgs:\n    blocksToRemove (list): List of block objects whose source should be excluded from the node's source code.\n\nReturns:\n    Node: A new Node instance reflecting the modified source and context of this group.\n\"\"\"",
                    "source_code": "source = self.source.copy()\n\n\t\tfor block in blocksToRemove:\n\t\t\tsource -= block.fullSource\n\n\t\t#Depending on whether or not this is the file root (global frame)\n\t\t#, set a flag and the node name\n\t\tif self.parent:\n\t\t\tisFileRoot = False\n\t\t\tname = self.name\n\t\telse:\n\t\t\tisFileRoot = True\n\t\t\tname = self._generateRootNodeName(self.name.rsplit('/',1)[-1])\n\n\n\t\t#generate and append the node\n\t\treturn Node(name=name,source=source,definitionString=self.definitionString,parent=self,lineNumber=self.lineNumber,isFileRoot=isFileRoot)#isImplicit=True"
                },
                {
                    "docstring": "'''\n\t\tUsing the sourcecode before the block, try generating a function using all of the patterns we know about\n\t\tIf we can generate it, return a new group with the sourcecode within the block\n\t\t'''",
                    "first_doc": "\"\"\"\nAttempts to generate a new group from a source code block using known patterns.\n\nThis method extracts the portion of the source code before and within a specified block, then tries to create a new group using each pattern in the known patterns list. If a matching pattern is found and a new group is generated, it returns that group. If no pattern matches, it returns None.\n\nArgs:\n    openBracket: The index marking the start of the code block within the source code.\n    closeBracket: The index marking the end of the code block within the source code.\n\nReturns:\n    The newly generated group if a matching pattern is found; otherwise, None.\n\"\"\"",
                    "method_name": "newGroupFromBlock",
                    "second_doc": "\"\"\"\nAnalyzes a specific code block to identify if it matches any known structural patterns, facilitating further processing or visualization.\n\nThis method examines the source code surrounding and within a defined block, testing each registered pattern to determine if a recognized grouping can be established from the segment. By identifying such groupings, the tool can better map out relationships and structure within the codebase.\n\nArgs:\n    openBracket (int): Index indicating the start of the code block within the source.\n    closeBracket (int): Index indicating the end of the code block within the source.\n\nReturns:\n    Group: A newly created group corresponding to a matched pattern, or None if no patterns matched.\n\"\"\"",
                    "source_code": "preBlockSource = self.source[:openBracket]\n\t\tblockSource = self.source[openBracket:closeBracket+1]\n\n\t\tfor pattern in self.PATTERNS:\n\t\t\tnewGroup = self.newGroupFromSourcesAndPattern(preBlockSource,blockSource,pattern)\n\t\t\tif newGroup:\n\t\t\t\treturn newGroup\n\n\t\tif DEBUG:\n\t\t\tprint \"====================\"\n\t\t\tprint preBlockSource.sourceString[-100:]\n\t\t\tprint 'what is this?'\n\n\t\treturn None"
                },
                {
                    "docstring": "'''\n\t\tGiven a functionPattern to test for, sourcecode before the block, and sourcecode within the block,\n\t\tTry to generate a new group\n\n\n\t\t'''",
                    "first_doc": "\"\"\"\nAttempts to generate a new Group based on a matching function pattern found within the provided source code context.\n\nGiven a pattern to match a function signature, the method examines the source code preceding and within a code block to identify and extract a function definition. If a match is found, it constructs and returns an appropriate Group object, attaching it to the correct parent based on naming conventions and namespace.\n\nArgs:\n    self: The instance of the class.\n    preBlockSource: The source code content preceding the current code block; used for pattern searching and context extraction.\n    blockSource: The source code content inside the target code block; may represent the body of a function or group.\n    pattern: The pattern dictionary used to identify the function, which includes the matching regex and function type.\n\nReturns:\n    Group or None: Returns a new Group object initialized with name, source code, full source, definition string, parent group, line number, and function/anonymous function flags if a matching pattern is found; otherwise, returns None.\n\"\"\"",
                    "method_name": "newGroupFromSourcesAndPattern",
                    "second_doc": "\"\"\"\nIdentifies and extracts a function definition from the provided source code context based on a specified pattern, and creates a corresponding Group object to represent this function in the internal structure.\n\nThis method narrows the search for a function signature to the region following the last closed bracket, applies the given pattern to detect a function definition, and, if successful, constructs a Group instance with relevant metadata. Group assignment is determined by naming and namespace conventions, enabling hierarchical organization of code elements. This approach ensures accurate modeling of code structure for subsequent analysis and visualization.\n\nArgs:\n    self: The current Group instance serving as the context for the search and potential parent for the new Group.\n    preBlockSource: The code segment preceding the relevant code block, used to locate the function declaration context.\n    blockSource: The code inside the block, typically representing the body of the function.\n    pattern: A dictionary that includes a matching regex and the function type used to identify target function definitions.\n\nReturns:\n    Group or None: A new Group object representing the detected function definition with associated metadata if a matching pattern is found; otherwise, None.\n\"\"\"",
                    "source_code": "#We are looking for a function name\n\t\t#Start by limiting the search area to that inbetween the last closed bracket and here\n\t\t#Then, try to match the pattern\n\t\tlastBracket = preBlockSource.sourceString.rfind('}')\n\t\tif lastBracket == -1:\n\t\t\tlastBracket = 0\n\t\tmatch = pattern['pattern'].match(preBlockSource.sourceString[lastBracket:])\n\n\t\t#If we found a match, generate a group\n\t\tif match:\n\t\t\t#name the function\n\t\t\tif pattern['type']=='anonFunction':\n\t\t\t\tname = \"(anon)\"\n\t\t\telse:\n\t\t\t\tname = match.group(2)\n\n\t\t\t#determine what group to attach this to.\n\t\t\t#if there was a dot in the namespace, we might need to attach this to something other than the group it was defined within\n\t\t\tattachTo = self\n\t\t\tif '.' in name:\n\t\t\t\tnamespace, name = name.rsplit('.',1)\n\t\t\t\tgroup = self.findNamespace(namespace,self)\n\t\t\t\tif group:\n\t\t\t\t\tattachTo = group\n\n\t\t\t#generate the definition and line number\n\t\t\tdefinitionString = match.group(1)\n\t\t\tlineNumber = preBlockSource.getLineNumber(match.start(1)+lastBracket)\n\t\t\tfullSource = preBlockSource[lastBracket+match.start(1):]+blockSource\n\n\t\t\t#finally, generate the group\n\t\t\treturn Group(\n\t\t\t\tname=name\n\t\t\t\t,source=blockSource[1:-1] #source without the brackets\n\t\t\t\t,fullSource=fullSource\n\t\t\t\t,definitionString=definitionString\n\t\t\t\t,parent=attachTo\n\t\t\t\t,lineNumber=lineNumber\n\t\t\t\t,isFunction=pattern['type'] in ('function','anonFunction')\n\t\t\t\t,isAnon=pattern['type'] == 'anonFunction')\n\n\t\treturn None"
                },
                {
                    "docstring": null,
                    "method_name": "generateOrAppendToGroup",
                    "second_doc": "\"\"\"\nExamines the type of function delimiter at the specified node position and either generates a group for regular functions or adjusts the delimiter position for anonymous functions. This ensures the correct processing and classification of code blocks based on their syntactic structure.\n\nArgs:\n    node: An object representing the code element whose position is being analyzed.\n\nReturns:\n    None. The method generates or updates the internal representation of a group as a side effect.\n\"\"\"",
                    "source_code": "openDelimPos = self.source.openDelimPos(node.characterPos)\n\n\t\tif self.source.sourceString[openDelimPos] == '{':\n\t\t\t#this is a regular function, generate the group\n\t\t\tgroup = self.generateGroup(openDelimPos,node)\n\t\telif self.source.sourceString[openDelimPos] == '(':\n\t\t\t#declare as an anonymous function\n\t\t\t#the caller shall still be found by going one higher\n\t\t\twhile self.source.sourceString[openDelimPos] == '(':\n\t\t\t\topenDelimPos = self.source.openDelimPos(openDelimPos-1)\n\t\telse:\n\t\t\tprint 'what is this?'"
                }
            ],
            "name": "Group",
            "type": "class"
        },
        {
            "methods": [],
            "name": "SourceCode",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": "'''\n\t\tGenerate a group for the file. This will be a function group (isFunction=True)\n\t\tA function group can possibly call other groups.\n\t\t'''",
                    "first_doc": "\"\"\"\nGenerate a function group for the specified file.\n\nA function group represents a collection of related functions within the file and can potentially reference or call other groups.\n\nArgs:\n    name: The name to assign to the generated group.\n    source: The source code of the file to be grouped.\n\nReturns:\n    Group: A new Group object representing the file as a function group. The group's name is set to the specified name, its source and fullSource are set to the provided source code, and isFunction is set to True.\n\"\"\"",
                    "method_name": "generateFileGroup",
                    "second_doc": "\"\"\"\nCreates a group representation of all functions found within a given source file, encapsulating both source content and group metadata. This enables subsequent processing, organization, and analysis of the file\u2019s functional structure within the broader system.\n\nArgs:\n    name (str): The label to assign to the created group.\n    source (str): The full source code of the file to be analyzed and grouped.\n\nReturns:\n    Group: An object that encapsulates the file\u2019s functions as a unified group, containing the source code and relevant metadata for downstream use.\n\"\"\"",
                    "source_code": "return Group(name=name,source=source,fullSource=source,isFunction=True)"
                }
            ],
            "name": "Mapper",
            "type": "class"
        }
    ],
    "code2flow/code2flowlib/languages/python.py": [
        {
            "details": {
                "docstring": null,
                "method_name": "getIndent",
                "second_doc": "\"\"\"\nExtracts the indentation whitespace following a specified position in the source string. This helps determine the structural layout of code by identifying nesting and block scopes.\n\nArgs:\n    sourceString (str): The string containing source code to analyze.\n    colonPos (int): The index in the string from which indentation should be detected.\n\nReturns:\n    str: The whitespace characters representing indentation after colonPos, or triggers a debugger on failure.\n\"\"\"",
                "source_code": "try:\n\t\treturn indentPattern.search(sourceString[colonPos:]).group(1)\n\texcept:\n\t\tpdb.set_trace()"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "generateSameScopePatterns",
                    "second_doc": "\"\"\"\nGenerates pattern representations for elements within the same scope as the current node by invoking the corresponding method from the parent class. This is done to accurately capture local relationships that are relevant for code structure analysis and visualization.\n\nReturns:\n    list: Patterns representing relationships or features of code elements within the same scope.\n\"\"\"",
                    "source_code": "patterns = super(Node,self).generateSameScopePatterns()\n\t\treturn patterns"
                },
                {
                    "docstring": null,
                    "method_name": "generateNamespacePatterns",
                    "second_doc": "\"\"\"\nGenerates a list of regular expression patterns corresponding to the namespace of the current node, including custom handling for initialization methods. This pattern matching facilitates accurate identification of function definitions and calls within hierarchical code structures.\n\nArgs:\n    None\n\nReturns:\n    list: A list of compiled regular expression patterns used to match relevant function call and definition namespaces in the source code.\n\"\"\"",
                    "source_code": "patterns = super(Node,self).generateNamespacePatterns()\n\t\tif self.name == '__init__':\n\t\t\tpattern = re.compile(r\"\\W%s\\(\"%self.parent.getNamespace())\n\t\t\tpatterns.append(pattern)\n\t\t#if self.name == '__str__':\n\t\t#\tpattern = re.compule(r\"\\Wstr\\(\\s*%s\\s*\\)\"%self.\n\t\treturn patterns"
                },
                {
                    "docstring": null,
                    "method_name": "determineNodeType",
                    "second_doc": "\"\"\"\nDetermines whether the current node represents an initializer method (__init__) and sets the isInitNode flag accordingly.\n\nThis enables differentiation of constructor nodes from other functions, which is useful when analyzing and visualizing the structure and entry points within object-oriented code.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "if self.name == '__init__':\n\t\t\tself.isInitNode = True\n\t\telse:\n\t\t\tself.isInitNode = False"
                },
                {
                    "docstring": "'''\n\t\tReturns whether we can safely delete this node\n\t\t'''",
                    "first_doc": "\"\"\"\nDetermines if the current node can be safely deleted from the structure.\n\nArgs:\n    self: The instance of the node to check for deletion eligibility.\n    edges: A list of edge objects that may be connected to the node.\n\nReturns:\n    bool: True if the node can be safely deleted (is extraneous), False otherwise.\n\"\"\"",
                    "method_name": "isExtraneous",
                    "second_doc": "\"\"\"\nChecks if the current node, assumed to be a root, has no connected edges and therefore can be removed without affecting the connectivity of the graph.\n\nArgs:\n    edges (list): A list of edge objects possibly linked to the current node.\n\nReturns:\n    bool: True if the node is a root and not connected to any edge; False otherwise.\n\"\"\"",
                    "source_code": "if self.isRoot():\n\t\t\tfor edge in edges:\n\t\t\t\tif edge.node0 == self or edge.node1 == self:\n\t\t\t\t\treturn False\n\t\t\telse:\n\t\t\t\treturn True\n\t\treturn False"
                },
                {
                    "docstring": null,
                    "method_name": "isRoot",
                    "second_doc": "\"\"\"\nDetermines whether the current node is considered the root in the context of the data structure by checking if its parent node has no parent itself. This check helps identify the entry point or starting node for traversing or organizing hierarchical code representations.\n\nArgs:\n    self: The current Node instance to evaluate.\n\nReturns:\n    bool: True if the node is determined to be the root node (i.e., its parent has no parent), otherwise False.\n\"\"\"",
                    "source_code": "if self.parent.parent:\n\t\t\treturn False\n\t\telse:\n\t\t\treturn True"
                },
                {
                    "docstring": null,
                    "method_name": "linksTo",
                    "second_doc": "\"\"\"\nDetermines whether this node contains a reference or call to another node, accounting for file imports, namespaces, and various calling conventions.\n\nThis check enables precise mapping of inter-function relationships across files and namespaces, which is crucial for building accurate call graphs and visualizing how code components interact.\n\nArgs:\n    other (Node): The node representing the potential target of a call or reference.\n\nReturns:\n    bool: True if this node links to (calls or references) the other node, otherwise False.\n\"\"\"",
                    "source_code": "importNamespace = ''\n\n\t\t#If this is in a different file, figure out what namespace to use\n\t\tif self._getFileGroup() != other._getFileGroup():\n\t\t\timportPaths = other.parent.getImportPaths(self._getFileName())\n\n\t\t\tfor importPath in importPaths:\n\t\t\t\tregularImport = re.compile(r\"^import\\s+%s\\s*$\"%re.escape(importPath),re.MULTILINE)\n\t\t\t\tcomplexImport = re.compile('^from\\s%s\\simport\\s(?:\\*|(?:.*?\\W%s\\W.*?))\\s*$'%(re.escape(importPath),re.escape(other.name)),re.MULTILINE)\n\t\t\t\t#print importPath\n\t\t\t\t#print self.parent._getFileGroup().name\n\t\t\t\tif regularImport.search(self._getFileGroup().source.sourceString):\n\t\t\t\t\timportNamespace += importPath\n\t\t\t\t\tbreak\n\t\t\t\telif complexImport.search(self._getFileGroup().source.sourceString):\n\t\t\t\t\tbreak\n\t\t\telse:\n\t\t\t\treturn False\n\n\t\tif not other.isRoot():\n\t\t\timportNamespace = importNamespace + '.' + other.parent.name if importNamespace else other.parent.name\n\n\t\t#If the naive functionName (e.g. \\Wmyfunc\\( ) appears anywhere in this sourceString, check whether it is actually THAT function\n\t\tmatch = other.pattern.search(self.source.sourceString)\n\t\tif match:\n\t\t\tmatchPos = match.start(1)\n\t\t\thasDot = self.source.sourceString[matchPos-1] == '.'\n\n\t\t\t#if the other function is in the global namespace and this call is not referring to any namespace, return true\n\t\t\tif other.isRoot() and not hasDot: #TODO js will require the 'window' namespace integrated somehow\n\t\t\t\treturn True\n\n\t\t\t#if the other is part of a namespace and we are looking for a namspace\n\t\t\tif hasDot:\n\n\t\t\t\t#try finding the namespace of the called object\n\t\t\t\ttry:\n\t\t\t\t\tprefixSearchLine = self.source.sourceString[:matchPos].split('\\n')[-1]\n\t\t\t\t\t#print '\"%s\"'%prefixSearchLine\n\t\t\t\t\tnamespace = self.namespaceBeforeDotPattern.search(prefixSearchLine).group(1)\n\t\t\t\texcept AttributeError:\n\t\t\t\t\t#will not find a namespace if the object is in an array or something else weird\n\t\t\t\t\t#fall through this function because we can still check for init node\n\t\t\t\t\tnamespace = None\n\n\t\t\t\t#If the namespaces are the same, that is a match\n\t\t\t\tif namespace == importNamespace:# and self._getFileGroup() == other._getFileGroup(): #+ other.name\n\t\t\t\t\treturn True\n\n\t\t\t\t#if they are part of the same namespace, we can check for the 'self' keyword\n\t\t\t\tif other.parent == self.parent and namespace == self.sameScopeKeyword:\n\t\t\t\t\treturn True\n\n\t\t\t\t#If a new object was created prior to this call and that object calls this function, that is a match\n\t\t\t\tnewObjectMatch = other.parent.newObjectAssignedPattern.search(self.source.sourceString)\n\t\t\t\tif newObjectMatch and namespace == importNamespace + newObjectMatch.group(1):\n\t\t\t\t\treturn True\n\n\n\t\t#TODO put in try in case isInitNode not defined\n\t\tif other.isInitNode and other.parent.newObjectPattern.search(self.source.sourceString):\n\t\t\treturn True\n\n\t\treturn False"
                }
            ],
            "name": "Node",
            "type": "class"
        },
        {
            "methods": [],
            "name": "Edge",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": "'''\n\t\tGenerate a new group\n\n\t\tThe only thing special about groups in python is they are delimited by indent\n\t\tThis makes things a little bit easier\n\t\t'''",
                    "first_doc": "\"\"\"\nInitializes a new group, configuring its indentation and generating nodes.\n\nThis constructor sets up group-related attributes, generates nodes, and, if this is the root group, also initiates subgroup and root node creation.\n\nArgs:\n    self: The object instance.\n\nClass Fields Initialized:\n    indent: Stores the indentation level for the group.\n    parent: Reference to the parent group, if any (may be set by superclass/init).\n    nodes: Collection of nodes belonging to this group.\n    \nReturns:\n    None. This method initializes the group instance and its associated properties.\n\"\"\"",
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes a new group by setting its indentation, preparing its node collection, and triggering node and subgroup generation as appropriate.\n\nThis constructor organizes the group\u2019s internal structure so that it can accurately represent hierarchical relationships and node memberships. It ensures that nodes are generated with the correct context, and that the root group initializes all necessary subgroups and a root node, thereby constructing the foundational elements for further processing.\n\nArgs:\n    indent (str): The string used for indentation of this group, influencing formatting and hierarchy visualization.\n    **kwargs: Additional keyword arguments for parent class initialization.\n\nReturns:\n    None. This method prepares the group instance along with its associated nodes and subgroups to represent a segment of a call graph structure.\n\"\"\"",
                    "source_code": "self.indent = indent\n\n\t\tsuper(Group,self).__init__(**kwargs)\n\n\t\t#If this is the root node, set indent to nothing\n\t\t#if not self.parent:\n\t\t#\tself.indent = ''\n\n\t\t#with the indent set, we can now generate nodes\n\t\tself._generateNodes()\n\n\t\t#If this is the root node, continue generating subgroups and nodes\n\t\tif not self.parent:\n\t\t\tself.generateSubgroups()\n\t\t\tself.nodes.append(self.generateRootNode())"
                },
                {
                    "docstring": null,
                    "method_name": "trimGroups",
                    "second_doc": "\"\"\"\nRemoves unnecessary or redundant members from the groups to ensure that only the essential elements contributing to the execution flow are retained.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "pass"
                },
                {
                    "docstring": "'''\n\t\tFind all function definitions, generate the nodes, and append them\n\t\t'''",
                    "first_doc": "\"\"\"\nFinds all function definitions in the source string, generates corresponding nodes, and appends them to the nodes list.\n\nArgs:\n    self: The instance of the class.\n\nReturns:\n    None: This method does not return a value; it updates the `nodes` field of the class.\n\"\"\"",
                    "method_name": "_generateNodes",
                    "second_doc": "\"\"\"\nIdentifies all function definitions within the source code and creates corresponding internal representation nodes, adding them to the group's node list. This facilitates building a structured model of all functions present in the source, which is essential for further structural analysis.\n\nArgs:\n    self: The instance of the Group class containing the source code and node list.\n\nReturns:\n    None: The method modifies the `nodes` attribute in-place by appending new nodes; no value is returned.\n\"\"\"",
                    "source_code": "functionPatterns = self.generateFunctionPatterns()\n\t\tfor pattern in functionPatterns:\n\t\t\tfunctionMatches = pattern.finditer(self.source.sourceString)\n\t\t\tfor functionMatch in functionMatches:\n\t\t\t\tnode = self.generateNode(functionMatch)\n\t\t\t\tself.nodes.append(node)"
                },
                {
                    "docstring": "'''\n\t\tReturn the regex for function definition at this indent level\n\t\t'''",
                    "first_doc": "\"\"\"\nGenerates a regular expression pattern for matching Python function definitions at the current indentation level.\n\nArgs:\n    self: The instance of the class on which this method is called.\n\nReturns:\n    list: A list containing a compiled regular expression object that can match function definitions at the specified indent level.\n\"\"\"",
                    "method_name": "generateFunctionPatterns",
                    "second_doc": "\"\"\"\nCreates a regular expression pattern that matches Python function definitions at the specific indentation level recorded in the instance. This approach ensures only top-level or appropriately nested functions are detected during parsing, which is essential for accurately mapping function structure.\n\nArgs:\n    self: The Group instance containing the target indentation information.\n\nReturns:\n    list: A list with a compiled regular expression object that matches Python function definition lines at the captured indentation.\n\"\"\"",
                    "source_code": "indent = self.indent.replace(' ',r'\\s').replace('\t',r'\\t')\n\t\treturn [re.compile(r\"^%sdef\\s(\\w+)\\s*\\(.*?\\)\\s*\\:\"%indent,re.MULTILINE|re.DOTALL)]"
                },
                {
                    "docstring": null,
                    "method_name": "generateSubgroups",
                    "second_doc": "\"\"\"\nIdentifies class definitions within the current code segment and creates subgroup objects for each discovered class, preserving hierarchy and context information.\n\nArgs:\n    None\n\nReturns:\n    None\n\nWhy:\n    This method iterates through class definitions in the current code context to build a structured, hierarchical representation of code components. Doing so enables the system to maintain an accurate internal model of how classes (and their relationships) are organized, which is essential for reliable analysis and visualization of code structure.\n\"\"\"",
                    "source_code": "classMatches = self.classPattern.finditer(self.source.sourceString)\n\t\tfor classMatch in classMatches:\n\t\t\tname = classMatch.group(1)\n\t\t\tdefinitionString = classMatch.group(0)\n\t\t\tcolonPos = classMatch.end(0)\n\t\t\tindent = getIndent(colonPos=colonPos,sourceString=self.source.sourceString)\n\t\t\tsource = self.source.getSourceInBlock(colonPos=colonPos)\n\t\t\tfullSource = self.source.getSourceInBlock(colonPos=colonPos,fullSource=True)\n\t\t\tlineNumber = self.source.getLineNumber(colonPos)\n\t\t\tclassGroup = Group(name=name,definitionString=definitionString,indent=indent,source=source,fullSource=fullSource,parent=self,lineNumber=lineNumber)\n\t\t\tself.subgroups.append(classGroup)"
                },
                {
                    "docstring": null,
                    "method_name": "generateNewObjectPattern",
                    "second_doc": "\"\"\"\nGenerates a compiled regular expression pattern to match constructor calls for this group's associated object type.\n\nArgs:\n    None\n\nReturns:\n    re.Pattern: A compiled regular expression object that matches instances where the group's name is used to instantiate an object, facilitating the identification of new object creations in the analyzed source code.\n\"\"\"",
                    "source_code": "return re.compile(r'%s\\s*\\('%self.name)"
                },
                {
                    "docstring": null,
                    "method_name": "generateNewObjectAssignedPattern",
                    "second_doc": "\"\"\"\nGenerates and compiles a regular expression pattern that matches assignment statements where an object is instantiated using the group's associated name. This facilitates the detection of object initialization patterns within source code analysis.\n\nArgs:\n    None\n\nReturns:\n    re.Pattern: A compiled regular expression pattern for matching object assignments involving the group's name.\n\"\"\"",
                    "source_code": "return re.compile(r'(\\w)\\s*=\\s*%s\\s*\\('%self.name)"
                },
                {
                    "docstring": null,
                    "method_name": "generateRootNode",
                    "second_doc": "\"\"\"\nCreates and returns a root node representing the entry point of a group, initializing it with an automatically generated name and implicit node source. This method encapsulates the group as a single node so that its contents can be managed and visualized as part of a larger code structure.\n\nArgs:\n    None\n\nReturns:\n    Node: The generated root node, with a unique name and implicit source, and this group as its parent.\n\"\"\"",
                    "source_code": "name = self._generateRootNodeName()\n\t\tsource = self.generateImplicitNodeSource()\n\t\treturn Node(name=name,definitionString=None,source=source,parent=self) #isImplicit=True"
                },
                {
                    "docstring": "'''\n\t\tFind all of the code not in any subnode, string it together, and return it as the implicit node\n\t\t'''",
                    "first_doc": "\"\"\"\nFinds and concatenates all code segments not included in any subnode or subgroup, returning them as the implicit node source.\n\nArgs:\n    self: Instance of the class containing the method.\n\nReturns:\n    The combined source code that does not belong to any subnode or subgroup, representing the implicit node.\n\"\"\"",
                    "method_name": "generateImplicitNodeSource",
                    "second_doc": "\"\"\"\nIdentifies and collects all code segments within the group that are not explicitly associated with any contained nodes or subgroups, and returns their combined source code as the residual definition for further analysis.\n\nArgs:\n    self: The Group instance from which to extract unassigned source code.\n\nReturns:\n    The combined code segments from the group's source that are not covered by any node or subgroup, suitable for inclusion as the group's implicit node.\n\"\"\"",
                    "source_code": "source = self.source.copy()\n\t\tfor node in self.nodes:\n\t\t\tsource -= node.fullSource\n\n\t\t\t#source =source.remove(node.definitionString)\n\n\t\tfor group in self.subgroups:\n\t\t\tsource -= group.fullSource\n\t\t\t'''\n\t\t\tsource.remove(group.source.sourceString)\n\t\t\tif group.definitionString:\n\t\t\t\t#print group.definitionString\n\n\t\t\t\tsource = source.remove(group.definitionString)\n\t\t\t'''\n\t\treturn source"
                },
                {
                    "docstring": "'''\n\t\tReturn the relative and absolute paths the other filename would use to import this module\n\t\t'''",
                    "first_doc": "\"\"\"\nReturns the possible relative and absolute import paths for this module when imported from another file.\n\nArgs:\n    self: The instance of the class.\n    importerFilename: The filename of the importing module.\n\nReturns:\n    list: A list containing both the relative and absolute import paths applicable for importing this module from the specified file.\n\"\"\"",
                    "method_name": "getImportPaths",
                    "second_doc": "\"\"\"\nGenerates a list of valid relative and absolute import paths for this module based on where it is being imported from, enabling accurate resolution of dependencies and references during code parsing and analysis.\n\nArgs:\n    importerFilename (str): The filename of the module initiating the import.\n\nReturns:\n    list of str: All import paths that can be used to import this module from the given importing file.\n\"\"\"",
                    "source_code": "paths = self._getRelativeImportPaths(importerFilename)+self._getAbsoluteImportPaths()\n\t\treturn paths"
                },
                {
                    "docstring": null,
                    "method_name": "_getRelativeImportPaths",
                    "second_doc": "\"\"\"\nCompute relative import paths between this group's file and an importing file by analyzing their directory structures. This helps establish correct Python import statements reflecting their filesystem relationship.\n\nArgs:\n    importerFilename (str): The absolute or relative path to the file that will import from this group's module.\n\nReturns:\n    list: A list where the first element is the relative import path (as used in a Python import statement),\n          and the second element (if present) is the parent directory name of this group's file.\n\"\"\"",
                    "source_code": "thisFullPath = os.path.abspath(self._getFileName())\n\t\tthisFullPathList = thisFullPath.split('/')\n\n\t\timporterFullPath = os.path.abspath(importerFilename)\n\t\timporterFullPathList = importerFullPath.split('/')\n\n\t\t#pop off shared directories\n\t\twhile True:\n\t\t\ttry:\n\t\t\t\tassert thisFullPathList[0] == importerFullPathList[0]\n\t\t\t\tthisFullPathList.pop(0)\n\t\t\t\timporterFullPathList.pop(0)\n\t\t\texcept AssertionError:\n\t\t\t\tbreak\n\n\t\trelativePath = ''\n\n\t\t#if the importer's unique directory path is longer than 1,\n\t\t#then we will have to back up a bit to the last common shared directory\n\t\trelativePath += '.'*len(importerFullPathList)\n\n\t\t#add this path from the last common shared directory\n\t\trelativePath += '.'.join(thisFullPathList)\n\t\tpaths = []\n\n\t\tpaths.append(relativePath)\n\n\t\ttry:\n\t\t\tpaths.append(thisFullPathList[-2:-1][0])\n\t\texcept:\n\t\t\tpass\n\n\t\treturn paths"
                },
                {
                    "docstring": null,
                    "method_name": "_getAbsoluteImportPaths",
                    "second_doc": "\"\"\"\nGenerates a list of possible absolute import paths for the current file, starting from the file name and including higher-level directory modules.\n\nArgs:\n    None\n\nReturns:\n    list: A list of strings representing possible absolute import paths, ordered from the file/module itself up through its parent directories.\n\nWhy:\n    This method provides all valid import path variations for a file, allowing for accurate resolution of module dependencies and structure during source code analysis.\n\"\"\"",
                    "source_code": "paths = []\n\n\t\tpathArray = os.path.realpath(self._getFileName()).split('/')[::-1]\n\t\tbuildPathList = pathArray[0]\n\t\tpathArray = pathArray[1:]\n\n\t\tpaths.append(buildPathList)\n\t\tfor elem in pathArray:\n\t\t\tif elem:\n\t\t\t\tbuildPathList = elem + '.' + buildPathList\n\t\t\t\tpaths.append(buildPathList)\n\n\t\treturn paths"
                },
                {
                    "docstring": "'''\n\t\tUsing the name match, generate the name, source, and parent of this node\n\n\t\tgroup(0) is the entire definition line ending at the new block delimiter like:\n\t\t\tdef myFunction(a,b,c):\n\t\tgroup(1) is the identifier name like:\n\t\t\tmyFunction\n\t\t'''",
                    "first_doc": "\"\"\"\nGenerates a Node object representing this code block based on pattern match results.\n\nArgs:\n    self: The instance of the class calling the method.\n    reMatch: The regex match object containing the details of the code block header.\n\nReturns:\n    Node: A Node instance initialized with the name, definition string, source code, full source code, parent node, character position, and line number corresponding to the matched code block.\n\"\"\"",
                    "method_name": "generateNode",
                    "second_doc": "\"\"\"\nConstructs a Node object representing a code block, extracting crucial metadata such as its name, definition, source code, and contextual information, based on the results of a pattern match. This enables systematic organization and further analysis of code structure.\n\nArgs:\n    reMatch: The regex match object containing details about the code block header.\n\nReturns:\n    Node: An instance that includes the block's name, definition string, extracted source code, complete source, parent reference, character position, and line number within the file.\n\"\"\"",
                    "source_code": "name = reMatch.group(1)\n\t\tdefinitionString = reMatch.group(0)\n\n\t\tnewBlockDelimPos = reMatch.end(0)\n\t\tbeginIdentifierPos = reMatch.start(1)\n\n\t\tsource = self.source.getSourceInBlock(newBlockDelimPos)\n\t\tfullSource = self.source.getSourceInBlock(newBlockDelimPos,fullSource=True)\n\t\tlineNumber = self.source.getLineNumber(beginIdentifierPos)\n\t\treturn Node(name=name,definitionString=definitionString,source=source,fullSource=fullSource,parent=self,characterPos=beginIdentifierPos,lineNumber=lineNumber)"
                }
            ],
            "name": "Group",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": "'''\n\t\tOverwrites superclass method\n\t\t'''",
                    "first_doc": "\"\"\"\nRetrieves a block of source code in the current object, starting from a specific colon position.\n\nArgs:\n    self: The instance of the current object.\n    colonPos: The position of the colon in the source string from which to begin extracting the code block.\n\nReturns:\n    str: The source code block found after the given colon position, including proper indentation as determined from the source string.\n\"\"\"",
                    "method_name": "getSourceInBlock",
                    "second_doc": "\"\"\"\nExtracts and returns a contiguous block of source code following a specified colon position, preserving the relevant indentation and structure. This is necessary to accurately isolate logical code blocks, such as function bodies or indented suites, based on the language's syntax rules.\n\nArgs:\n    colonPos (int): The position of the colon in the source string from which to begin extracting the code block.\n\nReturns:\n    str: The block of source code that follows the given colon position, maintaining the indentation for proper context.\n\"\"\"",
                    "source_code": "indent = getIndent(colonPos,self.sourceString)\n\n\t\tendPos = colonPos\n\n\t\tlines = self.sourceString[colonPos:].split('\\n')[1:]\n\t\tfor line in lines:\n\t\t\tif line.startswith(indent) or line.strip()=='':\n\t\t\t\tendPos += len(line)+1 #+1 for the newlines lost\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\tif fullSource:\n\t\t\tstartPos = self.sourceString.rfind('\\n',0,colonPos)\n\t\t\tif startPos == -1:\n\t\t\t\tstartPos = 0\n\t\t\telse:\n\t\t\t\tstartPos += 1\n\t\telse:\n\t\t\tstartPos = colonPos+1\n\t\ttry:\n\t\t\treturn self[startPos:endPos]\n\t\texcept:\n\t\t\tpdb.set_trace()"
                }
            ],
            "name": "SourceCode",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": "'''\n\t\tGenerate a group for the file. Indent is implicitly none for this group\n\t\t'''",
                    "first_doc": "\"\"\"\nGenerates a group object for a file with no indentation.\n\nArgs:\n    name: The name to assign to the group.\n    source: The source content or data for the group.\n\nReturns:\n    Group: A new Group object initialized with the given name, source, and an empty indentation.\n\"\"\"",
                    "method_name": "generateFileGroup",
                    "second_doc": "\"\"\"\nCreates a new group representation for a given file without any indentation applied. This method ensures that each top-level file grouping starts without leading whitespace to maintain clarity and consistency during further processing or visualization.\n\nArgs:\n    name (str): The identifier to assign to the group.\n    source (str): The content or data to be associated with this group.\n\nReturns:\n    Group: An instance representing the file group with the specified name and source, initialized with no indentation.\n\"\"\"",
                    "source_code": "return Group(name=name,source=source,indent='')"
                }
            ],
            "name": "Mapper",
            "type": "class"
        }
    ],
    "code2flow/code2flowlib/mutablestring.py": [
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes the MString instance by converting the input string into a list of its characters.\n\nArgs:\n    char (str): The input string to be split into individual characters.\n\nReturns:\n    None: This is an initializer and does not return a value.\n\nWhy:\n    Breaking the string into a list of characters allows for more flexible processing and analysis of the string on a per-character basis, which can be essential for tasks such as parsing or analyzing code structures.\n\"\"\"",
                    "source_code": "self.chars = list(char)"
                },
                {
                    "docstring": null,
                    "method_name": "__repr__",
                    "second_doc": "\"\"\"\nReturns a string representation of the MString object by concatenating its characters. \n\nThis allows inspection and debugging by reconstructing the original text stored in the object.\n\nReturns:\n    str: The string formed by joining all characters in the internal list.\n\"\"\"",
                    "source_code": "return \"\".join(self.chars)"
                },
                {
                    "docstring": null,
                    "method_name": "__setitem__",
                    "second_doc": "\"\"\"\nReplaces the character at the specified index in the MString instance with the given character. \n\nArgs:\n    index (int): The position at which to update the character.\n    char (str): The new character to insert at the specified index.\n\nReturns:\n    None\n\nThis enables controlled modification of string data, allowing for precise updates as part of processing or analyzing textual representations.\n\"\"\"",
                    "source_code": "self.chars[index] = char"
                },
                {
                    "docstring": null,
                    "method_name": "__getitem__",
                    "second_doc": "\"\"\"\nRetrieve one or multiple characters from the string-like object.\n\nArgs:\n    index (int or slice): The position or range of positions to access within the character collection.\n\nReturns:\n    str: A single character if an integer index is provided, or a concatenated string of characters if a slice is given.\n\nThis allows flexible access to elements or subsequences, supporting efficient inspection and manipulation of the underlying character data.\n\"\"\"",
                    "source_code": "if type(index) == slice:\n\t\t\treturn \"\".join(self.chars[index])\n\t\treturn self.chars[index]"
                },
                {
                    "docstring": null,
                    "method_name": "__delitem__",
                    "second_doc": "\"\"\"\nRemoves the character at the specified index from the string representation.\n\nArgs:\n    index (int): The position of the character to delete.\n\nReturns:\n    None\n\nWhy:\n    Enables modification of the internal character sequence by allowing specific elements to be deleted, supporting flexible manipulation of string data.\n\"\"\"",
                    "source_code": "del self.chars[index]"
                },
                {
                    "docstring": null,
                    "method_name": "__add__",
                    "second_doc": "\"\"\"\nRaises a NotImplementedError to indicate that addition between instances of this class is not supported or intentionally left undefined.\n\nArgs:\n    other (Any): The object to add to this instance.\n\nReturns:\n    NotImplemented: This method does not return a value but raises an exception instead, signaling that the operation is not implemented.\n\nWhy:\n    This method is not implemented to explicitly prevent or defer the support for addition operations, encouraging users to focus on meaningful manipulations relevant to this type of object in the context of code analysis or visualization tasks.\n\"\"\"",
                    "source_code": "raise NotImplementedError"
                },
                {
                    "docstring": null,
                    "method_name": "__len__",
                    "second_doc": "\"\"\"\nReturns the number of characters contained in this MString instance.\n\nThis allows the MString object to interact seamlessly with Python's built-in len() function by reporting the length of its underlying character data.\n\nReturns:\n    int: The count of characters stored in the MString.\n\"\"\"",
                    "source_code": "return len(self.chars)"
                },
                {
                    "docstring": null,
                    "method_name": "append",
                    "second_doc": "\"\"\"\nAppends a given element to the end of the character sequence maintained by this object.\n\nArgs:\n    other: The character or string element to append to the current MString instance.\n\nReturns:\n    None. The method modifies the MString in place to extend its content.\n\nWhy:\n    This method enables dynamic extension of the underlying character sequence, supporting flexible accumulation and manipulation of string data during source code parsing or transformation tasks.\n\"\"\"",
                    "source_code": "self.chars.append(other)"
                },
                {
                    "docstring": null,
                    "method_name": "strip",
                    "second_doc": "\"\"\"\nRemoves leading and trailing whitespace from the string representation of the current object to ensure clean and accurate string values for further processing.\n\nArgs:\n    None\n\nReturns:\n    str: The contents of the object as a string with surrounding whitespace removed.\n\"\"\"",
                    "source_code": "return str(self).strip()"
                },
                {
                    "docstring": null,
                    "method_name": "find",
                    "second_doc": "\"\"\"\nSearches for the first occurrence of a specified substring within the string, starting from a given position.\n\nArgs:\n    what (str): The substring to search for within the string.\n    startAt (int): The position in the string at which to begin the search.\n\nReturns:\n    int: The index of the first occurrence of the substring. Returns -1 if the substring is not found.\n\nThis method enables precise location of specific text patterns, which is essential for identifying code elements and relationships during analysis.\n\"\"\"",
                    "source_code": "return str(self).find(what,startAt)"
                }
            ],
            "name": "MString",
            "type": "class"
        }
    ],
    "code2flow/code2flowlib/nesting.py": [
        {
            "details": {
                "docstring": "'''\n\tGiven a string and two delimiters, return the text between the first pair of delimiters after 'startAt'\n\t'''",
                "first_doc": "\"\"\"\nExtracts the substring found between the first occurrence of delimiterA and the corresponding closing delimiterB from the given string, starting at the specified position.\n\nArgs:\n    string: The input string to search within.\n    delimiterA: The opening delimiter indicating the start of the region to extract.\n    delimiterB: The closing delimiter indicating the end of the region to extract.\n\nReturns:\n    str: The substring found between delimiterA and delimiterB. Returns an empty string if delimiters are not found or do not match.\n\"\"\"",
                "method_name": "extractBetween",
                "second_doc": "\"\"\"\nLocates and extracts the portion of text found between the first occurrence of delimiterA and its corresponding delimiterB within a string, starting from a given position. This is useful for parsing or isolating code or text segments that are enclosed by known delimiters, facilitating structured analysis or manipulation.\n\nArgs:\n    string (str): The string to search within.\n    delimiterA (str): The opening delimiter that marks the beginning of the region to extract.\n    delimiterB (str): The closing delimiter that marks the end of the region to extract.\n    startAt (int): The position in the string to start searching from.\n\nReturns:\n    str: The text found between delimiterA and delimiterB, or an empty string if the delimiters are not found or matched.\n\"\"\"",
                "source_code": "string = string[startAt:]\n\tdelimSize = len(delimiterA)\n\tif delimSize != len(delimiterB):\n\t\traise Exception(\"delimiterA must be the same length as delimiterB\")\n\n\tstart = string.find(delimiterA)\n\tif start == -1:\n\t\treturn ''\n\tstart += delimSize\n\n\tendPos = endDelimPos(string[start:],delimiterA,delimiterB)\n\tif endPos != -1:\n\t\treturn string[start:start+endPos]\n\telse:\n\t\treturn ''"
            },
            "type": "function"
        },
        {
            "details": {
                "docstring": null,
                "method_name": "endDelimPos",
                "second_doc": "\"\"\"\nFinds the position in the input string where a matching closing delimiter is found, taking into account potential nested delimiters.\n\nArgs:\n    string (str): The text in which to search for a balanced pair of delimiters.\n    delimiterA (str): The opening delimiter to match.\n    delimiterB (str): The closing delimiter to match.\n\nReturns:\n    int: The index of the final character of the matching closing delimiter, or -1 if no balanced pair is found.\n\nRaises:\n    Exception: If the opening and closing delimiters are not the same length.\n\nWhy:\n    This method identifies the boundary of a block of text enclosed by matching delimiters, which is essential for correctly parsing nested structures.\n\"\"\"",
                "source_code": "delimSize = len(delimiterA)\n\tif delimSize != len(delimiterB):\n\t\traise Exception(\"delimiterA must be the same length as delimiterB\")\n\n\tcount = 1\n\ti = 0\n\twhile i<len(string) and count>0:\n\t\ttmp = string[i:i+delimSize]\n\t\tif tmp==delimiterA:\n\t\t\tcount += 1\n\t\t\ti+=delimSize\n\t\telif tmp==delimiterB:\n\t\t\tcount -= 1\n\t\t\ti+=delimSize\n\t\telse:\n\t\t\ti+=1\n\n\tif count == 0:\n\t\treturn i-delimSize\n\telse:\n\t\treturn -1"
            },
            "type": "function"
        },
        {
            "details": {
                "docstring": "'''\n\tGo back to find the nearest open bracket without a corresponding close\n\t'''",
                "first_doc": "\"\"\"\nFinds the position of the matching opening bracket for a closing bracket at a given position in a string.\n\nArgs:\n    pos: The index position in the string to start searching backwards from. The string to search in should be accessible to the method as a variable.\n\nReturns:\n    int: The index position of the matching opening bracket if found; otherwise, returns 0.\n\"\"\"",
                "method_name": "openBracketPos",
                "second_doc": "\"\"\"\nTraverses a string backward from a specified position to locate the matching opening bracket for a closing bracket. This is necessary for accurately parsing code structures and delineating code blocks.\n\nArgs:\n    pos (int): The index in the string to begin searching backward from. The string variable should be accessible to the method.\n\nReturns:\n    int: The index of the corresponding opening bracket if found; otherwise, 0.\n\"\"\"",
                "source_code": "count = 0\n\ti = pos\n\twhile i>=0 and count>=0:\n\t\tif string[i] in ('}',')'):\n\t\t\tcount += 1\n\t\telif string[i] in ('{','('):\n\t\t\tcount -= 1\n\t\ti-=1\n\n\tif count==-1:\n\t\treturn i+1\n\telse:\n\t\treturn 0"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes a SourceFile instance by accepting either a file object or a source code string. Reads file contents if a file is provided, or uses the input string directly. \n\nArgs:\n    strorfile (file or str): The source code provided as a file object or a string.\n\nReturns:\n    None\n\nThis method standardizes the input format for source code, ensuring consistent downstream processing regardless of the input type.\n\"\"\"",
                    "source_code": "if type(strorfile) == file:\n\t\t\twith open(strorfile) as f:\n\t\t\t\tself.sourceStr = f.read()\n\t\telif type(strorfile) == str:\n\t\t\tself.sourceStr = strorfile"
                },
                {
                    "docstring": null,
                    "method_name": "_calculateNesting",
                    "second_doc": "\"\"\"\nAnalyzes the source string to determine levels of code block nesting.\n\nThis method iterates through the contents of the source file and is a preliminary step in understanding the structural organization of source code elements. By identifying nesting, it supports further analysis of how control and logic blocks are structured.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "while i<len(self.sourceStr):\n\t\t\tpass"
                },
                {
                    "docstring": null,
                    "method_name": "isGlobalScope",
                    "second_doc": "\"\"\"\nDetermines if the given position in the source file is at the outermost (global) level rather than inside any nested block.\n\nArgs:\n    pos: The position in the source file to check.\n\nReturns:\n    bool: True if the position is at global scope (not nested in any structure), False otherwise.\n\nThis helps distinguish top-level constructs from those defined within nested blocks or functions, supporting accurate code structure mapping.\n\"\"\"",
                    "source_code": "return nestedLevel(pos) == 0"
                },
                {
                    "docstring": null,
                    "method_name": "nestedLevel",
                    "second_doc": "\"\"\"\nDetermines the nesting level of code sections within the source file to help clarify hierarchical relationships between different parts of the code.\n\nReturns:\n    int: The depth of nesting for a given code section within the file, where a higher value indicates deeper containment in the code structure.\n\"\"\"",
                    "source_code": "pass"
                }
            ],
            "name": "SourceFile",
            "type": "class"
        }
    ],
    "code2flow/setup.py": [],
    "code2flow/testscripts/__init__.py": [],
    "code2flow/testscripts/pysimple.py": [
        {
            "details": {
                "docstring": null,
                "method_name": "b",
                "second_doc": "\"\"\"\nCalls the function c to advance the analysis or processing step.\n\nArgs:\n    None\n\nReturns:\n    None\n\nThis method executes the next step in a larger workflow, supporting further progress or data collection in the sequence of function operations.\n\"\"\"",
                "source_code": "c()"
            },
            "type": "function"
        },
        {
            "details": {
                "docstring": null,
                "method_name": "c",
                "second_doc": "\"\"\"\nPrints a message indicating execution within the 'c' function.\n\nThis output can assist in tracing program flow, especially when visualizing or analyzing function calls in a codebase.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                "source_code": "print 'this is c'"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "f",
                    "second_doc": "\"\"\"\nExecutes a sequence of operations by invoking function b and then initializing a specific component within an external module. This method helps ensure that each required operation is performed in the correct order for further processing.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "b()\n\t\tpysimple2.h.a()"
                }
            ],
            "name": "e",
            "type": "class"
        }
    ],
    "code2flow/testscripts/pysimple2.py": [
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "a",
                    "second_doc": "\"\"\"\nPrints a message and contains an unreachable recursive call to itself, serving as a placeholder for potential future logic or as a marker for code analysis tools.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "print \"do nothing\t\"\n\t\tif False:\n\t\t\tself.a()"
                }
            ],
            "name": "h",
            "type": "class"
        }
    ],
    "code2flow/testscripts/pysimple3.py": [
        {
            "details": {
                "docstring": null,
                "method_name": "g",
                "second_doc": "\"\"\"\nInvokes the a() method of object h after printing an identifier message.  \nThis enables tracking function calls for mapping out the program's execution sequence.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                "source_code": "print 'my name is g'\n\th.a()"
            },
            "type": "function"
        }
    ],
    "code2flow/testscripts/urllib2.py": [
        {
            "details": {
                "docstring": null,
                "method_name": "urlopen",
                "second_doc": "\"\"\"\nOpens the specified URL, reusing an existing opener if available to optimize repeated URL requests and maintain consistent request handling throughout the process.\n\nArgs:\n    url (str): The URL to open.\n    data (bytes, optional): Data to send in a POST request to the URL.\n\nReturns:\n    HTTPResponse: The response object resulting from the URL request.\n\"\"\"",
                "source_code": "global _opener\n    if _opener is None:\n        _opener = build_opener()\n    return _opener.open(url, data)"
            },
            "type": "function"
        },
        {
            "details": {
                "docstring": null,
                "method_name": "install_opener",
                "second_doc": "\"\"\"\nSet the global opener to the provided opener instance.\n\nBy assigning a new opener object to a module-level variable, this function allows for customization of how resources (such as URLs or files) are opened during analysis. This can facilitate specialized processing, mocking, or extension of source data retrieval and preprocessing mechanisms.\n\nArgs:\n    opener: The opener object to use for future resource opening operations.\n\nReturns:\n    None\n\"\"\"",
                "source_code": "global _opener\n    _opener = opener"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes the URLError instance with the provided reason.\n\nArgs:\n    reason: The underlying cause or explanation for the URL-related error.\n\nReturns:\n    None\n\nWhy:\n    Storing the reason for the error allows for clearer error reporting and easier troubleshooting when issues related to URLs are encountered during processing.\n\"\"\"",
                    "source_code": "self.reason = reason"
                },
                {
                    "docstring": null,
                    "method_name": "__str__",
                    "second_doc": "\"\"\"\nReturns a human-readable string representation of the URLError, summarizing the reason for the error.\n\nThis method aids debugging and error reporting by producing a concise error message that describes what went wrong during a URL operation.\n\nReturns:\n    str: A formatted error message indicating the reason for the URL error.\n\"\"\"",
                    "source_code": "return '<urlopen error %s>' % self.reason"
                }
            ],
            "name": "URLError",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes an HTTPError instance by storing error details such as status code, message, headers, response file pointer, and the associated URL. This information is captured to enable comprehensive reporting and handling of HTTP errors encountered during network interactions, facilitating error tracing and debugging in automated analysis workflows.\n\nArgs:\n    fp: A file-like object representing the response body from the HTTP request.\n    hdrs: Headers returned in the HTTP response.\n    url: The URL associated with the HTTP error.\n    code: The HTTP status code indicating the error type.\n    msg: A message describing the HTTP error.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.__super_init(fp, hdrs, url)\n        self.code = code\n        self.msg = msg\n        self.hdrs = hdrs\n        self.fp = fp\n        # XXX\n        self.filename = url"
                },
                {
                    "docstring": null,
                    "method_name": "__str__",
                    "second_doc": "\"\"\"\nReturns a human-readable string representation of the HTTP error, displaying both the error code and its associated message.\n\nArgs:\n    self: The instance of the HTTPError containing the code and message attributes.\n\nReturns:\n    str: A string describing the HTTP error in the format \"HTTP Error <code>: <msg>\".\n    \nWhy:\n    This provides clear and concise feedback about HTTP errors encountered during program execution, facilitating debugging and error tracing by conveying essential information in a standard format.\n\"\"\"",
                    "source_code": "return 'HTTP Error %s: %s' % (self.code, self.msg)"
                },
                {
                    "docstring": null,
                    "method_name": "__del__",
                    "second_doc": "\"\"\"\nEnsures that any associated file-like resource is properly closed when the HTTPError object is about to be destroyed.\n\nThis method helps prevent resource leaks by closing the underlying resource automatically when the object is no longer in use.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "if self.fp:\n            self.fp.close()"
                }
            ],
            "name": "HTTPError",
            "type": "class"
        },
        {
            "methods": [],
            "name": "GopherError",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes a Request object by parsing the provided URL, storing any associated data, and setting up HTTP headers for later use.\n\nArgs:\n    url (str): The URL to be processed for the request.\n    data (Any): Optional data payload to be submitted with the request.\n    headers (dict): Dictionary of HTTP headers to include in the request.\n\nReturns:\n    None\n\nWhy:\n    The method organizes information from the URL and headers to prepare the request object for consistent and structured handling in subsequent processing steps.\n\"\"\"",
                    "source_code": "self.__original = unwrap(url)\n        self.type = None\n        # self.__r_type is what's left after doing the splittype\n        self.host = None\n        self.port = None\n        self.data = data\n        self.headers = {}\n        self.headers.update(headers)"
                },
                {
                    "docstring": null,
                    "method_name": "__getattr__",
                    "second_doc": "\"\"\"\nIntercepts attribute access for internal request attributes, initializing them if necessary to ensure correct and complete attribute values are available on demand.\n\nArgs:\n    attr (str): The name of the attribute being accessed.\n\nReturns:\n    Any: The value of the requested attribute after performing any required lazy initialization.\n\nRaises:\n    AttributeError: If the requested attribute does not exist or cannot be initialized.\n\"\"\"",
                    "source_code": "if attr[:12] == '_Request__r_':\n            name = attr[12:]\n            if hasattr(Request, 'get_' + name):\n                getattr(self, 'get_' + name)()\n                return getattr(self, attr)\n        raise AttributeError, attr"
                },
                {
                    "docstring": null,
                    "method_name": "add_data",
                    "second_doc": "\"\"\"\nAssigns the provided data to the request instance for further processing or analysis.\n\nArgs:\n    data: The data to be attached to the request instance.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.data = data"
                },
                {
                    "docstring": null,
                    "method_name": "has_data",
                    "second_doc": "\"\"\"\nCheck whether the current request instance contains any associated data.\n\nReturns:\n    bool: True if the request has data attached; otherwise, False.\n\nThis method helps determine if there is content to be processed or analyzed for the given request, which impacts subsequent handling or parsing steps.\n\"\"\"",
                    "source_code": "return self.data is not None"
                },
                {
                    "docstring": null,
                    "method_name": "get_data",
                    "second_doc": "\"\"\"\nRetrieve the parsed data associated with the current request.\n\nThis method enables access to structured information that has been extracted and stored, allowing further operations or transformations on this data as needed to support subsequent processing steps.\n\nReturns:\n    dict: The data parsed and stored within the current Request instance.\n\"\"\"",
                    "source_code": "return self.data"
                },
                {
                    "docstring": null,
                    "method_name": "get_full_url",
                    "second_doc": "\"\"\"\nRetrieves the original URL associated with this request instance.\n\nThis method returns the initial URL before any processing or transformation, enabling accurate tracing and reference within the context of analyzing source relationships.\n\nReturns:\n    str: The unmodified, original URL tied to the request.\n\"\"\"",
                    "source_code": "return self.__original"
                },
                {
                    "docstring": null,
                    "method_name": "get_type",
                    "second_doc": "\"\"\"\nRetrieves the type component of the original URL, parsing and caching it if necessary. This ensures that subsequent operations have access to a validated and recognized URL type.\n\nArgs:\n    None\n\nReturns:\n    str: The type of the URL.\n\nRaises:\n    ValueError: If the URL type cannot be determined from the original string.\n\"\"\"",
                    "source_code": "if self.type is None:\n            self.type, self.__r_type = splittype(self.__original)\n            if self.type is None:\n                raise ValueError, \"unknown url type: %s\" % self.__original\n        return self.type"
                },
                {
                    "docstring": null,
                    "method_name": "get_host",
                    "second_doc": "\"\"\"\nRetrieves and caches the host component from the request type attribute, decoding it if necessary.\n\nThis method ensures consistent access to the host data for further analysis or processing of code structure.\n\nArgs:\n    None\n\nReturns:\n    str or None: The decoded host component of the request, or None if not available.\n\"\"\"",
                    "source_code": "if self.host is None:\n            self.host, self.__r_host = splithost(self.__r_type)\n            if self.host:\n                self.host = unquote(self.host)\n        return self.host"
                },
                {
                    "docstring": null,
                    "method_name": "get_selector",
                    "second_doc": "\"\"\"\nRetrieve the selector value associated with the request, used to uniquely identify or route requests within the system.\n\nReturns:\n    str: The selector value for the current request.\n\"\"\"",
                    "source_code": "return self.__r_host"
                },
                {
                    "docstring": null,
                    "method_name": "set_proxy",
                    "second_doc": "\"\"\"\nConfigure the request to use a proxy server by specifying its host and type. This setup allows routing of requests through the desired intermediary, enabling features such as tracing, inspection, or bypassing network restrictions.\n\nArgs:\n    host (str): The address or hostname of the proxy server.\n    type (str): The protocol or type of proxy being used (e.g., 'http', 'https').\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.host, self.type = host, type\n        self.__r_host = self.__original"
                },
                {
                    "docstring": null,
                    "method_name": "add_header",
                    "second_doc": "\"\"\"\nAdds or updates an HTTP header for the current request, enabling customization of request metadata required for accurate communication with external systems.\n\nArgs:\n    key (str): The header field name to add or update.\n    val (str): The value to assign to the header field.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.headers[key] = val"
                }
            ],
            "name": "Request",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes the OpenerDirector instance by setting up default request headers and internal data structures for managing handlers and request processing logic.\n\nArgs:\n    self: The instance of the OpenerDirector being initialized.\n\nReturns:\n    None\n\nWhy:\n    This setup is necessary to correctly handle different types of URL requests and responses, as well as to properly manage and delegate tasks among various request handlers.\n\"\"\"",
                    "source_code": "server_version = \"Python-urllib/%s\" % __version__\n        self.addheaders = [('User-agent', server_version)]\n        # manage the individual handlers\n        self.handlers = []\n        self.handle_open = {}\n        self.handle_error = {}"
                },
                {
                    "docstring": null,
                    "method_name": "add_handler",
                    "second_doc": "\"\"\"\nRegisters a handler object to enable processing of specific protocols and error types during resource handling. The method inspects the handler for methods corresponding to particular protocols (ending with '_open') or error handlers (containing '_error_'), mapping them accordingly for future use during resource opening and error handling operations.\n\nArgs:\n    handler: The handler object to be registered. It should define methods that correspond to protocol openers or error handlers, following naming conventions (e.g., 'http_open', 'ftp_error_404').\n\nReturns:\n    None. The function modifies the internal handler mappings for the director and adds the handler to the active handler list if relevant methods are found.\n\nWhy:\n    This is necessary to enable flexible, protocol-specific or error-specific processing during resource access, allowing dynamic extension of the resource-handling logic by attaching handlers that know how to deal with particular scenarios.\n\"\"\"",
                    "source_code": "added = 0\n        for meth in dir(handler):\n            if meth[-5:] == '_open':\n                protocol = meth[:-5]\n                if self.handle_open.has_key(protocol):\n                    self.handle_open[protocol].append(handler)\n                else:\n                    self.handle_open[protocol] = [handler]\n                added = 1\n                continue\n            i = meth.find('_')\n            j = meth[i+1:].find('_') + i + 1\n            if j != -1 and meth[i+1:j] == 'error':\n                proto = meth[:i]\n                kind = meth[j+1:]\n                try:\n                    kind = int(kind)\n                except ValueError:\n                    pass\n                dict = self.handle_error.get(proto, {})\n                if dict.has_key(kind):\n                    dict[kind].append(handler)\n                else:\n                    dict[kind] = [handler]\n                self.handle_error[proto] = dict\n                added = 1\n                continue\n        if added:\n            self.handlers.append(handler)\n            handler.add_parent(self)"
                },
                {
                    "docstring": null,
                    "method_name": "__del__",
                    "second_doc": "\"\"\"\nEnsures that system resources or connections managed by the instance are properly released when the object is destroyed.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.close()"
                },
                {
                    "docstring": null,
                    "method_name": "close",
                    "second_doc": "\"\"\"\nCloses all handler objects managed by this director, releasing any associated resources and resetting the handler list.\n\nThis cleanup ensures that resources held by various handlers, such as open files or network connections, are properly released when the director is no longer needed.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "for handler in self.handlers:\n            handler.close()\n        self.handlers = []"
                },
                {
                    "docstring": null,
                    "method_name": "_call_chain",
                    "second_doc": "\"\"\"\nAttempts to delegate a specific operation to the first appropriate handler in a predefined chain and returns its result if available.\n\nArgs:\n    chain (dict): A mapping from operation type to iterables of handler objects.\n    kind (str): The operation type to be handled.\n    meth_name (str): The name of the method to invoke on each handler.\n    *args: Arguments to pass to the handler method.\n\nReturns:\n    Any: The result returned by the handler method, or None if no handler returns a result.\n\nWhy:\n    This method facilitates the flexible processing of operations by allowing multiple handlers to be chained, ensuring that requests are managed by the most suitable handler available. This promotes modular and extensible handling of operations without hardcoding the logic for each case.\n\"\"\"",
                    "source_code": "handlers = chain.get(kind, ())\n        for handler in handlers:\n            func = getattr(handler, meth_name)\n\n            result = func(*args)\n            if result is not None:\n                return result"
                },
                {
                    "docstring": null,
                    "method_name": "open",
                    "second_doc": "\"\"\"\nProcesses a given URL or request object, applying a series of handlers to determine how it should be opened and processed. This method manages different request types and ensures an appropriate handler is used for each case, facilitating structured and consistent request handling.\n\nArgs:\n    fullurl: A URL as a string, or a Request object representing the resource to process.\n    data: Optional data to include with the request.\n\nReturns:\n    The result from the handler that successfully processes the request, or the result of an 'unknown' handler if no other matches are found.\n\nWhy:\n    This approach enables a flexible and extensible mechanism for delegating the handling of various types of requests to specific handlers, ensuring that each resource is accessed and processed with the most suitable logic.\n\"\"\"",
                    "source_code": "if isinstance(fullurl, (types.StringType, types.UnicodeType)):\n            req = Request(fullurl, data)\n        else:\n            req = fullurl\n            if data is not None:\n                req.add_data(data)\n        assert isinstance(req, Request) # really only care about interface\n\n        result = self._call_chain(self.handle_open, 'default',\n                                  'default_open', req)\n        if result:\n            return result\n\n        type_ = req.get_type()\n        result = self._call_chain(self.handle_open, type_, type_ + \\\n                                  '_open', req)\n        if result:\n            return result\n\n        return self._call_chain(self.handle_open, 'unknown',\n                                'unknown_open', req)"
                },
                {
                    "docstring": null,
                    "method_name": "error",
                    "second_doc": "\"\"\"\nHandles errors raised during a protocol request by dispatching to the appropriate error handler method. For certain protocols like HTTP and HTTPS, uses protocol-specific handlers and falls back to a default handler if a specific error method isn't found. This allows for flexible and granular error processing tailored to each protocol or error scenario.\n\nArgs:\n    proto (str): The protocol name (e.g., 'http', 'https', etc.).\n    *args: Additional arguments containing error information.\n\nReturns:\n    The result from the error handler if one is found and executed, otherwise the result from the default handler (if applicable), or None if no handlers apply.\n\"\"\"",
                    "source_code": "if proto in ['http', 'https']:\n            # XXX http[s] protocols are special-cased\n            dict = self.handle_error['http'] # https is not different than http\n            proto = args[2]  # YUCK!\n            meth_name = 'http_error_%d' % proto\n            http_err = 1\n            orig_args = args\n        else:\n            dict = self.handle_error\n            meth_name = proto + '_error'\n            http_err = 0\n        args = (dict, proto, meth_name) + args\n        result = self._call_chain(*args)\n        if result:\n            return result\n\n        if http_err:\n            args = (dict, 'default', 'http_error_default') + orig_args\n            return self._call_chain(*args)"
                }
            ],
            "name": "OpenerDirector",
            "type": "class"
        },
        {
            "details": {
                "docstring": "\"\"\"Create an opener object from a list of handlers.\n\n    The opener will use several default handlers, including support\n    for HTTP and FTP.  If there is a ProxyHandler, it must be at the\n    front of the list of handlers.  (Yuck.)\n\n    If any of the handlers passed as arguments are subclasses of the\n    default handlers, the default handlers will not be used.\n    \"\"\"",
                "first_doc": "\"\"\"\nCreates and configures an OpenerDirector instance with a set of default and user-provided handlers.\n\nThis method initializes an OpenerDirector and attaches default network handlers, such as proxy, HTTP, FTP, and file handlers. It also allows for customization by incorporating custom handlers, ensuring that no duplicate handler types are added. The final opener integrates all requested functionality and is ready for use in network operations.\n\nReturns:\n    OpenerDirector: An instance of OpenerDirector populated with the appropriate handlers for managing network requests.\n\"\"\"",
                "method_name": "build_opener",
                "second_doc": "\"\"\"\nInitializes an OpenerDirector instance equipped with standard and user-supplied handlers, while ensuring no redundant handler types are included.\n\nThis approach ensures flexibility and extensibility when handling network requests, allowing users to customize or override default behaviors according to their requirements.\n\nArgs:\n    handlers (list): A list of handler classes or instances to be included or to override corresponding default handlers.\n\nReturns:\n    OpenerDirector: An object configured with the selected handlers, ready to manage and process network operations.\n\"\"\"",
                "source_code": "opener = OpenerDirector()\n    default_classes = [ProxyHandler, UnknownHandler, HTTPHandler,\n                       HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                       FTPHandler, FileHandler]\n    if hasattr(httplib, 'HTTPS'):\n        default_classes.append(HTTPSHandler)\n    skip = []\n    for klass in default_classes:\n        for check in handlers:\n            if inspect.isclass(check):\n                if issubclass(check, klass):\n                    skip.append(klass)\n            elif isinstance(check, klass):\n                skip.append(klass)\n    for klass in skip:\n        default_classes.remove(klass)\n\n    for klass in default_classes:\n        opener.add_handler(klass())\n\n    for h in handlers:\n        if inspect.isclass(h):\n            h = h()\n        opener.add_handler(h)\n    return opener"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "add_parent",
                    "second_doc": "\"\"\"\nAssigns a parent handler to the current handler instance.\n\nArgs:\n    parent: The handler object that will be set as the parent of this handler.\n\nReturns:\n    None\n\nWhy:\n    Setting a parent handler enables the organization of handlers into a hierarchical structure, allowing the flow of information or context between related components during analysis and visualization of call relationships.\n\"\"\"",
                    "source_code": "self.parent = parent"
                },
                {
                    "docstring": null,
                    "method_name": "close",
                    "second_doc": "\"\"\"\nCleans up the handler's state by removing the reference to its parent object.\n\nThis prevents further interactions or data sharing with the parent, ensuring proper disconnection and supporting internal resource management.\n\nArgs:\n    None\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.parent = None"
                }
            ],
            "name": "BaseHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "http_error_default",
                    "second_doc": "\"\"\"\nHandles HTTP errors by raising an HTTPError with relevant request and response information.\n\nArgs:\n    req: The request object associated with the HTTP transaction.\n    code: The HTTP status code that triggered the error.\n    msg: The error message received from the server.\n    hdrs: The headers returned in the HTTP response.\n    fp: A file-like object containing the response body.\n\nReturns:\n    None. This method always raises an HTTPError to signal that an HTTP request failed and to propagate error details for further processing.\n\nWhy:\n    By raising a detailed HTTPError, this method enables higher-level logic to handle network failures and server responses consistently, supporting robust error handling and facilitating program stability during code analysis operations.\n\"\"\"",
                    "source_code": "raise HTTPError(req.get_full_url(), code, msg, hdrs, fp)"
                }
            ],
            "name": "HTTPDefaultErrorHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "http_error_302",
                    "second_doc": "\"\"\"\nHandles HTTP 302 redirect responses by extracting the new target URL from the response headers, constructing a new request for the redirected URL, and managing redirect tracking to prevent infinite loops. This ensures robust navigation through multiple redirects during HTTP interactions.\n\nArgs:\n    req (Request): The original HTTP request object that received the 302 redirect.\n    fp (file-like object): The file-like object containing the HTTP response body.\n    code (int): The HTTP status code (expected to be 302).\n    msg (str): The HTTP status message.\n    headers (dict): The HTTP response headers.\n\nReturns:\n    Response: The result of opening the new redirected request, or raises an HTTPError if a redirect loop is detected.\n\"\"\"",
                    "source_code": "if headers.has_key('location'):\n            newurl = headers['location']\n        elif headers.has_key('uri'):\n            newurl = headers['uri']\n        else:\n            return\n        newurl = urlparse.urljoin(req.get_full_url(), newurl)\n\n        # XXX Probably want to forget about the state of the current\n        # request, although that might interact poorly with other\n        # handlers that also use handler-specific request attributes\n        new = Request(newurl, req.get_data())\n        new.error_302_dict = {}\n        if hasattr(req, 'error_302_dict'):\n            if len(req.error_302_dict)>10 or \\\n               req.error_302_dict.has_key(newurl):\n                raise HTTPError(req.get_full_url(), code,\n                                self.inf_msg + msg, headers, fp)\n            new.error_302_dict.update(req.error_302_dict)\n        new.error_302_dict[newurl] = newurl\n\n        # Don't close the fp until we are sure that we won't use it\n        # with HTTPError.\n        fp.read()\n        fp.close()\n\n        return self.parent.open(new)"
                }
            ],
            "name": "HTTPRedirectHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes a ProxyHandler instance with a given set of proxy mappings, dynamically setting up methods to handle connections via the available proxy types.\n\nArgs:\n    proxies (mapping, optional): A mapping of proxy types to their respective URLs. If not provided, system proxy settings are used.\n\nReturns:\n    None\n\nWhy:\n    This initialization allows HTTP requests to be automatically routed through specified proxies, enabling flexible network access patterns without manual proxy management for each connection type.\n\"\"\"",
                    "source_code": "if proxies is None:\n            proxies = getproxies()\n        assert hasattr(proxies, 'has_key'), \"proxies must be a mapping\"\n        self.proxies = proxies\n        for type, url in proxies.items():\n            setattr(self, '%s_open' % type,\n                    lambda r, proxy=url, type=type, meth=self.proxy_open: \\\n                    meth(r, proxy, type))"
                },
                {
                    "docstring": null,
                    "method_name": "proxy_open",
                    "second_doc": "\"\"\"\nHandles the setting up of proxy authentication and configuration for a request. If the proxy type matches the original request type, the method allows standard processing to continue; otherwise, it restarts the process to ensure compatibility.\n\nArgs:\n    req: The request object that is to be sent through a proxy.\n    proxy: The proxy URL string to be used.\n\nReturns:\n    None if the request can continue with regular handling, or the result of re-opening the request through the parent handler if special proxy handling is needed.\n\nWhy:\n    This method ensures that requests are correctly prepared and routed through the specified proxy by managing proxy-related headers and handling protocol compatibility, enabling proper network communication when proxies are in use.\n\"\"\"",
                    "source_code": "orig_type = req.get_type()\n        type, r_type = splittype(proxy)\n        host, XXX = splithost(r_type)\n        if '@' in host:\n            user_pass, host = host.split('@', 1)\n            user_pass = base64.encodestring(unquote(user_pass)).strip()\n            req.add_header('Proxy-Authorization', 'Basic '+user_pass)\n        host = unquote(host)\n        req.set_proxy(host, type)\n        if orig_type == type:\n            # let other handlers take care of it\n            # XXX this only makes sense if the proxy is before the\n            # other handlers\n            return None\n        else:\n            # need to start over, because the other handlers don't\n            # grok the proxy's URL type\n            return self.parent.open(req)"
                }
            ],
            "name": "ProxyHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes a CustomProxy instance with protocol information, function reference, and proxy address.\n\nArgs:\n    proto: The protocol identifier associated with the proxy.\n    func: The function object to be proxied.\n    proxy_addr: The address used for proxying the function.\n\nReturns:\n    None\n\nWhy:\n    This method stores the necessary information about a function, its protocol, and address, enabling later processing or mapping of these elements in function relationship visualizations.\n\"\"\"",
                    "source_code": "self.proto = proto\n        self.func = func\n        self.addr = proxy_addr"
                },
                {
                    "docstring": null,
                    "method_name": "handle",
                    "second_doc": "\"\"\"\nProcesses the given request by invoking a user-defined function, and returns a status indicator based on the outcome. This approach allows for customizable handling logic, enabling dynamic branching or filtering within a broader system that analyzes code structures.\n\nArgs:\n    req: The request object to be processed, whose type and structure are determined by the user's implementation of self.func.\n\nReturns:\n    int: Returns 1 if the user-defined function evaluates the request as valid or actionable; otherwise, returns None.\n\"\"\"",
                    "source_code": "if self.func and self.func(req):\n            return 1"
                },
                {
                    "docstring": null,
                    "method_name": "get_proxy",
                    "second_doc": "\"\"\"\nRetrieves the network address used by this proxy.\n\nThis method is essential for obtaining the proxy's underlying address, which is required for routing network requests or connections through the correct endpoint.\n\nReturns:\n    str: The network address associated with this proxy instance.\n\"\"\"",
                    "source_code": "return self.addr"
                }
            ],
            "name": "CustomProxy",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes a CustomProxyHandler instance by setting up an internal container for proxies.\n\nArgs:\n    self: The instance of the CustomProxyHandler being initialized.\n\nReturns:\n    None\n\nThis initialization ensures that each handler starts with a clean state to track proxies, enabling further management and association of call relationships within source code analysis.\n\"\"\"",
                    "source_code": "self.proxies = {}"
                },
                {
                    "docstring": null,
                    "method_name": "proxy_open",
                    "second_doc": "\"\"\"\nAttempts to handle a given request by iterating through a list of proxies associated with the request's protocol. For each proxy, it checks if the proxy can handle the request, and if so, sets the proxy and delegates the request to the parent handler. Returns None if no suitable proxy is found.\n\nArgs:\n    req: The request object to be processed.\n\nReturns:\n    The response from the parent handler if a suitable proxy is found and used; otherwise, None.\n\"\"\"",
                    "source_code": "proto = req.get_type()\n        try:\n            proxies = self.proxies[proto]\n        except KeyError:\n            return None\n        for p in proxies:\n            if p.handle(req):\n                req.set_proxy(p.get_proxy())\n                return self.parent.open(req)\n        return None"
                },
                {
                    "docstring": null,
                    "method_name": "do_proxy",
                    "second_doc": "\"\"\"\nForwards the given request to the parent handler for processing.\n\nArgs:\n    req: The request object to be processed by the parent handler.\n\nReturns:\n    The response generated by the parent's open method.\n\nThis method delegates request handling to the parent to ensure consistent processing and integration within a chain of handlers.\n\"\"\"",
                    "source_code": "return self.parent.open(req)"
                },
                {
                    "docstring": null,
                    "method_name": "add_proxy",
                    "second_doc": "\"\"\"\nRegisters a proxy object under its corresponding protocol type within the handler's internal mapping.\n\nArgs:\n    cpo: The proxy object to be added, expected to have a 'proto' attribute indicating its protocol.\n\nReturns:\n    None\n\nWhy:\n    Organizing proxies by their protocol allows for efficient lookup and management based on protocol-specific requirements.\n\"\"\"",
                    "source_code": "if self.proxies.has_key(cpo.proto):\n            self.proxies[cpo.proto].append(cpo)\n        else:\n            self.proxies[cpo.proto] = [cpo]"
                }
            ],
            "name": "CustomProxyHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes an empty password storage for managing HTTP authentication credentials.\n\nArgs:\n    self: Instance of the HTTPPasswordMgr class.\n\nReturns:\n    None\n\nWhy:\n    This setup enables organized storage and retrieval of authentication information, which is essential for managing secure access to resources during automated code analysis or related operations.\n\"\"\"",
                    "source_code": "self.passwd = {}"
                },
                {
                    "docstring": null,
                    "method_name": "add_password",
                    "second_doc": "\"\"\"\nStores the given username and password associated with a specified realm and one or more URIs, allowing efficient credential retrieval for HTTP authentication scenarios.\n\nArgs:\n    realm (str): The authentication realm associated with the credentials.\n    uri (str or list of str): One or more URIs for which these credentials are valid.\n    user (str): The username to be used for the specified realm and URI(s).\n    passwd (str): The password corresponding to the username.\n\nReturns:\n    None\n\nWhy:\n    This method enables the organization and mapping of authentication credentials to specific realms and URIs, ensuring that the correct credentials can be efficiently retrieved and provided during HTTP requests that require authentication.\n\"\"\"",
                    "source_code": "if isinstance(uri, (types.StringType, types.UnicodeType)):\n            uri = [uri]\n        uri = tuple(map(self.reduce_uri, uri))\n        if not self.passwd.has_key(realm):\n            self.passwd[realm] = {}\n        self.passwd[realm][uri] = (user, passwd)"
                },
                {
                    "docstring": null,
                    "method_name": "find_user_password",
                    "second_doc": "\"\"\"\nSearches for and retrieves the stored username and password matching a given authentication URI and realm, if available.\n\nArgs:\n    authuri (str): The URI for which authentication credentials are being requested.\n    realm (str): The authentication realm to look up.\n\nReturns:\n    tuple: A tuple (username, password) if matching credentials are found for the specified realm and URI; otherwise, (None, None).\n\nWhy:\n    This method attempts to provide the appropriate credentials for user authentication in response to access requests, enabling seamless and secure authorization management for different protected areas within web services.\n\"\"\"",
                    "source_code": "domains = self.passwd.get(realm, {})\n        authuri = self.reduce_uri(authuri)\n        for uris, authinfo in domains.items():\n            for uri in uris:\n                if self.is_suburi(uri, authuri):\n                    return authinfo\n        return None, None"
                },
                {
                    "docstring": "\"\"\"Accept netloc or URI and extract only the netloc and path\"\"\"",
                    "first_doc": "\"\"\"\nExtracts and returns the netloc and path components from the given URI or netloc.\n\nArgs:\n    self: The instance of the class.\n    uri: The URI string or netloc to be parsed and reduced.\n\nReturns:\n    tuple: A tuple containing the extracted netloc and path. If no netloc is present, returns the path and '/' as default.\n\"\"\"",
                    "method_name": "reduce_uri",
                    "second_doc": "\"\"\"\nParses the provided URI or netloc and extracts its network location (netloc) and path components to facilitate consistent identification and handling of resource addresses.\n\nArgs:\n    self: Instance of HTTPPasswordMgr.\n    uri (str): URI string or netloc to be parsed and reduced.\n\nReturns:\n    tuple: (netloc, path) if netloc is present in the URI; otherwise, (path, '/'). This ensures a predictable output structure for downstream logic that requires uniform resource identifiers.\n\nWhy:\n    Consistently extracting the key address components from a URI simplifies handling credential scopes or permissions associated with specific network endpoints.\n\"\"\"",
                    "source_code": "parts = urlparse.urlparse(uri)\n        if parts[1]:\n            return parts[1], parts[2] or '/'\n        else:\n            return parts[2], '/'"
                },
                {
                    "docstring": "\"\"\"Check if test is below base in a URI tree\n\n        Both args must be URIs in reduced form.\n        \"\"\"",
                    "first_doc": "\"\"\"\nDetermines whether the given test URI is a sub-URI under the specified base URI.\n\nBoth arguments must be URIs in reduced form. The method checks if the test URI is equal to or extends the base URI path in a URI tree structure.\n\nArgs:\n    base: The base URI to compare against.\n    test: The test URI to check for subordination in the URI tree.\n\nReturns:\n    int: Returns 1 if the test URI is equal to or a sub-URI of the base URI; returns 0 otherwise.\n\"\"\"",
                    "method_name": "is_suburi",
                    "second_doc": "\"\"\"\nChecks if the test URI is identical to the base URI or located within its hierarchical path structure.\n\nThis helps determine logical containment or access scope between URIs for permissions, traversal safety, or linkage validation in systems that organize resources via URI schemes.\n\nArgs:\n    base (tuple): The reference URI in reduced tuple form (typically (scheme, path)).\n    test (tuple): The URI to be evaluated for hierarchical membership under the base.\n\nReturns:\n    int: 1 if the test URI is the same as or within the path scope of the base URI; 0 otherwise.\n\"\"\"",
                    "source_code": "if base == test:\n            return 1\n        if base[0] != test[0]:\n            return 0\n        common = posixpath.commonprefix((base[1], test[1]))\n        if len(common) == len(base[1]):\n            return 1\n        return 0"
                }
            ],
            "name": "HTTPPasswordMgr",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "find_user_password",
                    "second_doc": "\"\"\"\nAttempts to retrieve the user and password credentials for a given authentication URI, first by matching the provided realm, and if not found, by falling back to a default realm. This ensures that authentication checks proceed even when a specific realm match is unavailable, improving reliability when accessing protected resources.\n\nArgs:\n    realm (str or None): The authentication realm to match credentials for.\n    authuri (str): The URI identifying the protected resource.\n\nReturns:\n    tuple or (None, None): A tuple containing (user, password) if credentials are found, otherwise (None, None).\n\"\"\"",
                    "source_code": "user, password = HTTPPasswordMgr.find_user_password(self,realm,authuri)\n        if user is not None:\n            return user, password\n        return HTTPPasswordMgr.find_user_password(self, None, authuri)"
                }
            ],
            "name": "HTTPPasswordMgrWithDefaultRealm",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes the basic authentication handler with a password manager. If none is provided, a default HTTP password manager is created. This allows the handler to manage and retrieve credentials for HTTP requests as needed to handle authentication challenges.\n\nArgs:\n    password_mgr (HTTPPasswordMgr, optional): An instance responsible for storing and retrieving HTTP authentication credentials. Defaults to None, in which case a new password manager is created.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "if password_mgr is None:\n            password_mgr = HTTPPasswordMgr()\n        self.passwd = password_mgr\n        self.add_password = self.passwd.add_password"
                },
                {
                    "docstring": null,
                    "method_name": "http_error_auth_reqed",
                    "second_doc": "\"\"\"\nAttempts to handle HTTP authentication errors by examining the 'WWW-Authenticate' header. If Basic authentication is required, it retries the request using appropriate credentials.\n\nArgs:\n    host (str): The host from which the response originated.\n    req (Request): The original request object.\n    headers (dict): Response headers containing authentication details.\n\nReturns:\n    Response or None: Returns the result of a retried request with Basic authentication if applicable; otherwise, returns None.\n\nWhy:\n    This method enables automated handling of HTTP authentication challenges, ensuring seamless access to protected resources during network requests.\n\"\"\"",
                    "source_code": "authreq = headers.get(authreq, None)\n        if authreq:\n            mo = AbstractBasicAuthHandler.rx.match(authreq)\n            if mo:\n                scheme, realm = mo.groups()\n                if scheme.lower() == 'basic':\n                    return self.retry_http_basic_auth(host, req, realm)"
                },
                {
                    "docstring": null,
                    "method_name": "retry_http_basic_auth",
                    "second_doc": "\"\"\"\nAttempts to authenticate an HTTP request using stored credentials for a given realm and host.\n\nThis method retrieves the username and password associated with the provided authentication realm and host, encodes them using HTTP Basic Authentication, and attaches the appropriate header to the request. If valid credentials are found and not already present in the request, it retries the request with the authentication header added. This process helps ensure access to resources requiring authentication by transparently handling credential management and header injection.\n\nArgs:\n    req: The HTTP request object to which the authentication header may be added.\n    realm: The authentication realm for which credentials are sought.\n    host: The server host requiring authentication.\n\nReturns:\n    The HTTP response from retrying the request with authentication headers if credentials are found and used, or None if authentication is not possible or credentials are already present.\n\"\"\"",
                    "source_code": "user,pw = self.passwd.find_user_password(realm, host)\n        if pw:\n            raw = \"%s:%s\" % (user, pw)\n            auth = 'Basic %s' % base64.encodestring(raw).strip()\n            if req.headers.get(self.auth_header, None) == auth:\n                return None\n            req.add_header(self.auth_header, auth)\n            return self.parent.open(req)\n        else:\n            return None"
                }
            ],
            "name": "AbstractBasicAuthHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "http_error_401",
                    "second_doc": "\"\"\"\nHandles HTTP 401 Unauthorized errors by initiating authentication using credentials associated with the requested host.\n\nArgs:\n    req: The HTTP request object that triggered the 401 error.\n    headers: The headers returned by the server in response to the request.\n\nReturns:\n    The result of the authentication process, typically a new request object or response after providing appropriate credentials.\n\nWhy:\n    This method manages access control procedures for protected resources, ensuring only authorized requests proceed after a 401 error is encountered.\n\"\"\"",
                    "source_code": "host = urlparse.urlparse(req.get_full_url())[1]\n        return self.http_error_auth_reqed('www-authenticate',\n                                          host, req, headers)"
                }
            ],
            "name": "HTTPBasicAuthHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "http_error_407",
                    "second_doc": "\"\"\"\nHandles HTTP 407 Proxy Authentication Required responses by requesting proxy authentication credentials from the user or system. This enables the application to proceed with network requests routed through a proxy that demands authentication.\n\nArgs:\n    req: The HTTP request object triggering the 407 response.\n    headers: The headers from the 407 Proxy Authentication Required response.\n\nReturns:\n    A response with the appropriate proxy authentication applied, if credentials are available.\n\"\"\"",
                    "source_code": "host = req.get_host()\n        return self.http_error_auth_reqed('proxy-authenticate',\n                                          host, req, headers)"
                }
            ],
            "name": "ProxyBasicAuthHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes the authentication handler with a password manager. If no password manager is provided, a default one is created. This ensures the handler can securely store and manage user credentials for authorization processes.\n\nArgs:\n    passwd (HTTPPasswordMgr, optional): An existing password manager instance. If not provided, a new instance is created.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "if passwd is None:\n            passwd = HTTPPasswordMgr()\n        self.passwd = passwd\n        self.add_password = self.passwd.add_password"
                },
                {
                    "docstring": null,
                    "method_name": "http_error_auth_reqed",
                    "second_doc": "\"\"\"\nHandles HTTP authentication requests by detecting 'Digest' authentication schemes in response headers and initiating the appropriate retry mechanism.\n\nArgs:\n    req: The HTTP request object to be retried if authentication is required.\n    headers: A dictionary of HTTP headers received in the response.\n\nReturns:\n    The result of retrying the HTTP request with digest authentication if applicable, or None if not.\n    \nThis method ensures that authentication challenges are properly managed, enabling secure access to protected resources when required by the server.\n\"\"\"",
                    "source_code": "authreq = headers.get(self.auth_header, None)\n        if authreq:\n            kind = authreq.split()[0]\n            if kind == 'Digest':\n                return self.retry_http_digest_auth(req, authreq)"
                },
                {
                    "docstring": null,
                    "method_name": "retry_http_digest_auth",
                    "second_doc": "\"\"\"\nAttempts HTTP Digest authentication for the given request by parsing the server's authentication challenge and generating an appropriate authorization header. If the challenge can be satisfied, updates the request and retries, returning the new response. This process is necessary to provide valid credentials when an endpoint requires HTTP Digest authentication.\n\nArgs:\n    req: The HTTP request object to authenticate.\n    auth: The authentication challenge string returned by the server.\n\nReturns:\n    The HTTP response object if authentication succeeds, or None if repeated authentication is not required.\n\"\"\"",
                    "source_code": "token, challenge = auth.split(' ', 1)\n        chal = parse_keqv_list(parse_http_list(challenge))\n        auth = self.get_authorization(req, chal)\n        if auth:\n            auth_val = 'Digest %s' % auth\n            if req.headers.get(self.auth_header, None) == auth_val:\n                return None\n            req.add_header(self.auth_header, auth_val)\n            resp = self.parent.open(req)\n            return resp"
                },
                {
                    "docstring": null,
                    "method_name": "get_authorization",
                    "second_doc": "\"\"\"\nConstructs the HTTP Digest Authentication header for a request by processing server challenge parameters, retrieving user credentials, and computing the required digest response.\n\nArgs:\n    chal (dict): The challenge parameters provided by the server (e.g., 'realm', 'nonce', 'algorithm', 'opaque').\n    req: The HTTP request object that requires authentication.\n\nReturns:\n    str or None: The formatted 'Authorization' header string if all required information and algorithms are available; otherwise, None.\n\nWhy:\n    This method helps ensure secure, standards-compliant communication with servers requiring HTTP Digest Authentication, enabling the client to transparently authenticate itself based on the server's challenge parameters.\n\"\"\"",
                    "source_code": "try:\n            realm = chal['realm']\n            nonce = chal['nonce']\n            algorithm = chal.get('algorithm', 'MD5')\n            # mod_digest doesn't send an opaque, even though it isn't\n            # supposed to be optional\n            opaque = chal.get('opaque', None)\n        except KeyError:\n            return None\n\n        H, KD = self.get_algorithm_impls(algorithm)\n        if H is None:\n            return None\n\n        user, pw = self.passwd.find_user_password(realm,\n                                                  req.get_full_url())\n        if user is None:\n            return None\n\n        # XXX not implemented yet\n        if req.has_data():\n            entdig = self.get_entity_digest(req.get_data(), chal)\n        else:\n            entdig = None\n\n        A1 = \"%s:%s:%s\" % (user, realm, pw)\n        A2 = \"%s:%s\" % (req.has_data() and 'POST' or 'GET',\n                        # XXX selector: what about proxies and full urls\n                        req.get_selector())\n        respdig = KD(H(A1), \"%s:%s\" % (nonce, H(A2)))\n        # XXX should the partial digests be encoded too?\n\n        base = 'username=\"%s\", realm=\"%s\", nonce=\"%s\", uri=\"%s\", ' \\\n               'response=\"%s\"' % (user, realm, nonce, req.get_selector(),\n                                  respdig)\n        if opaque:\n            base = base + ', opaque=\"%s\"' % opaque\n        if entdig:\n            base = base + ', digest=\"%s\"' % entdig\n        if algorithm != 'MD5':\n            base = base + ', algorithm=\"%s\"' % algorithm\n        return base"
                },
                {
                    "docstring": null,
                    "method_name": "get_algorithm_impls",
                    "second_doc": "\"\"\"\nGenerates and returns cryptographic hash and key digest functions based on the specified algorithm, enabling secure encoding of authentication credentials.\n\nArgs:\n    algorithm (str): The name of the hash algorithm to use ('MD5' or 'SHA').\n    encode_digest (callable): Function to encode the digest output.\n\nReturns:\n    tuple: A tuple (H, KD) where H is a hash function for the provided algorithm and KD is a function for combining and hashing strings for authentication purposes.\n\nWhy:\n    By producing algorithm-specific hash and key digest functions, this method supports secure credential comparison and verification steps required by authentication schemes.\n\"\"\"",
                    "source_code": "if algorithm == 'MD5':\n            H = lambda x, e=encode_digest:e(md5.new(x).digest())\n        elif algorithm == 'SHA':\n            H = lambda x, e=encode_digest:e(sha.new(x).digest())\n        # XXX MD5-sess\n        KD = lambda s, d, H=H: H(\"%s:%s\" % (s, d))\n        return H, KD"
                },
                {
                    "docstring": null,
                    "method_name": "get_entity_digest",
                    "second_doc": "\"\"\"\nReturns a placeholder value indicating that no entity-specific digest is available.\n\nThis method exists to allow subclasses to implement logic for retrieving an authentication digest for a given entity if required. In the base class, it serves as a default that signifies no such information can be obtained.\n\nReturns:\n    None: Indicates that no digest value is provided by default.\n\"\"\"",
                    "source_code": "return None"
                }
            ],
            "name": "AbstractDigestAuthHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "http_error_401",
                    "second_doc": "\"\"\"\nHandle a 401 HTTP error by requesting authentication credentials using the 'www-authenticate' header for the requested host.\n\nArgs:\n    req: The HTTP request object that triggered the 401 error.\n    headers: The headers received in the HTTP response.\n\nReturns:\n    The result of the authentication request handling, typically updating or retrying the HTTP request with appropriate credentials.\n\nWhy:\n    This method processes authentication challenges to enable automated handling of protected resources, ensuring uninterrupted analysis or traversal of remote source files.\n\"\"\"",
                    "source_code": "host = urlparse.urlparse(req.get_full_url())[1]\n        self.http_error_auth_reqed('www-authenticate', host, req, headers)"
                }
            ],
            "name": "HTTPDigestAuthHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "http_error_407",
                    "second_doc": "\"\"\"\nHandles HTTP 407 (Proxy Authentication Required) errors by initiating authentication with the proxy server using the response headers and request host. This ensures that proper authentication is attempted when a proxy requests credentials.\n\nArgs:\n    req: The request object that triggered the proxy authentication challenge.\n    headers: The headers returned with the proxy authentication error.\n\nReturns:\n    None. The method processes the authentication requirement and may modify the request to include authentication information.\n\"\"\"",
                    "source_code": "host = req.get_host()\n        self.http_error_auth_reqed('proxy-authenticate', host, req, headers)"
                }
            ],
            "name": "ProxyDigestAuthHandler",
            "type": "class"
        },
        {
            "details": {
                "docstring": null,
                "method_name": "encode_digest",
                "second_doc": "\"\"\"\nConverts a given digest string into its hexadecimal representation by encoding each character as two hexadecimal digits.\n\nArgs:\n    digest (str): The string input representing the digest to be encoded.\n\nReturns:\n    str: Hexadecimal string representing the input digest.\n\nThis method encodes the digest into a hex format to provide a standardized, readable way of representing binary or hashed values for further processing or identification tasks within the system.\n\"\"\"",
                "source_code": "hexrep = []\n    for c in digest:\n        n = (ord(c) >> 4) & 0xf\n        hexrep.append(hex(n)[-1])\n        n = ord(c) & 0xf\n        hexrep.append(hex(n)[-1])\n    return ''.join(hexrep)"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "do_open",
                    "second_doc": "\"\"\"\nOpens an HTTP connection to the server specified in the request and sends either a GET or POST request based on the presence of data. Handles response retrieval and constructs a file-like object for further processing if the request is successful, or delegates error handling otherwise.\n\nArgs:\n    req: The request object containing the URL, headers, and optional data to be sent.\n\nReturns:\n    An addinfourl object wrapping the response file pointer, headers, and full URL if the HTTP response code is 200. Otherwise, invokes an error handler method with response details.\n\nRaises:\n    URLError: If the host is missing in the request or if there is a socket connection error.\n\nWhy:\n    This method encapsulates the mechanics of opening an HTTP connection and retrieving a response in order to abstract and automate communication with remote servers. This foundational step enables higher-level operations that require understanding remote interactions for further analysis, inspection, or processing.\n\"\"\"",
                    "source_code": "host = req.get_host()\n        if not host:\n            raise URLError('no host given')\n\n        try:\n            h = http_class(host) # will parse host:port\n            if req.has_data():\n                data = req.get_data()\n                h.putrequest('POST', req.get_selector())\n                if not req.headers.has_key('Content-type'):\n                    h.putheader('Content-type',\n                                'application/x-www-form-urlencoded')\n                if not req.headers.has_key('Content-length'):\n                    h.putheader('Content-length', '%d' % len(data))\n            else:\n                h.putrequest('GET', req.get_selector())\n        except socket.error, err:\n            raise URLError(err)\n\n        h.putheader('Host', host)\n        for args in self.parent.addheaders:\n            h.putheader(*args)\n        for k, v in req.headers.items():\n            h.putheader(k, v)\n        h.endheaders()\n        if req.has_data():\n            h.send(data)\n\n        code, msg, hdrs = h.getreply()\n        fp = h.getfile()\n        if code == 200:\n            return addinfourl(fp, hdrs, req.get_full_url())\n        else:\n            return self.parent.error('http', req, fp, code, msg, hdrs)"
                }
            ],
            "name": "AbstractHTTPHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "http_open",
                    "second_doc": "\"\"\"\nOpens an HTTP connection for the given request using the HTTP protocol. This method delegates the actual connection and data retrieval to a lower-level handler.\n\nArgs:\n    req: The request object containing all HTTP request data.\n\nReturns:\n    A response object resulting from the HTTP request, containing data and metadata from the server.\n\nWhy:\n    This approach abstracts the network communication process, allowing higher-level components to retrieve information from external sources without handling protocol-specific details.\n\"\"\"",
                    "source_code": "return self.do_open(httplib.HTTP, req)"
                }
            ],
            "name": "HTTPHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "unknown_open",
                    "second_doc": "\"\"\"\nHandles requests with an unrecognized or unsupported URL scheme by raising an error. This ensures that only valid and expected URL types are processed, preventing further handling of incorrect or malformed requests.\n\nArgs:\n    req: The request object containing the URL to be processed.\n\nRaises:\n    URLError: If the URL scheme of the request is not recognized.\n\"\"\"",
                    "source_code": "type = req.get_type()\n        raise URLError('unknown url type: %s' % type)"
                }
            ],
            "name": "UnknownHandler",
            "type": "class"
        },
        {
            "details": {
                "docstring": "\"\"\"Parse list of key=value strings where keys are not duplicated.\"\"\"",
                "first_doc": "\"\"\"\nParses a list of key-value assignment strings into a dictionary.\n\nEach element of the input list should have the format 'key=value'. If the value is enclosed in double quotes, the quotes are removed.\n\nArgs:\n    l: A list of strings, where each string is of the format 'key=value'.\n\nReturns:\n    dict: A dictionary mapping keys to their corresponding unquoted values.\n\"\"\"",
                "method_name": "parse_keqv_list",
                "second_doc": "\"\"\"\nConverts a list of key-value assignment strings into a dictionary to enable easy access to configuration or mapping parameters. This transforms structured text input into a programmatically useful data structure.\n\nArgs:\n    l (list of str): A list where each string has the format 'key=value'. If a value is surrounded by double quotes, those quotes will be stripped.\n\nReturns:\n    dict: Dictionary mapping each key to its corresponding unquoted value.\n\"\"\"",
                "source_code": "parsed = {}\n    for elt in l:\n        k, v = elt.split('=', 1)\n        if v[0] == '\"' and v[-1] == '\"':\n            v = v[1:-1]\n        parsed[k] = v\n    return parsed"
            },
            "type": "function"
        },
        {
            "details": {
                "docstring": "\"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comman-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.\n    \"\"\"",
                "first_doc": "\"\"\"\nParses a string as a comma-separated HTTP list, properly handling double-quoted values.\n\nThis method splits an HTTP header field value into a list of items, supporting proper parsing of double-quoted elements and raising an error for unbalanced quotes. Whitespace is stripped from each item.\n\nArgs:\n    s: A string representing a comma-separated HTTP list, possibly containing double-quoted items.\n\nReturns:\n    list: A list of strings, each representing an element from the HTTP list with leading and trailing whitespace removed. Raises a ValueError if quotes are unbalanced.\n\"\"\"",
                "method_name": "parse_http_list",
                "second_doc": "\"\"\"\nSplits a string formatted as a comma-separated list, ensuring segments with double quotes are handled correctly and that all quotes are balanced.\n\nThis method is necessary to accurately process list-like header values that may contain quoted substrings or nested delimiters, allowing for reliable tokenization before further analysis or manipulation.\n\nArgs:\n    s (str): The input string containing comma-separated values, which may include elements enclosed in double quotes.\n\nReturns:\n    list: A list of strings with surrounding whitespace removed for each item. Raises:\n        ValueError: If unbalanced double quotes are encountered in the input.\n\"\"\"",
                "source_code": "# XXX this function could probably use more testing\n\n    list = []\n    end = len(s)\n    i = 0\n    inquote = 0\n    start = 0\n    while i < end:\n        cur = s[i:]\n        c = cur.find(',')\n        q = cur.find('\"')\n        if c == -1:\n            list.append(s[start:])\n            break\n        if q == -1:\n            if inquote:\n                raise ValueError, \"unbalanced quotes\"\n            else:\n                list.append(s[start:i+c])\n                i = i + c + 1\n                continue\n        if inquote:\n            if q < c:\n                list.append(s[start:i+c])\n                i = i + c + 1\n                start = i\n                inquote = 0\n            else:\n                i = i + q\n        else:\n            if c < q:\n                list.append(s[start:i+c])\n                i = i + c + 1\n                start = i\n            else:\n                inquote = 1\n                i = i + q + 1\n    return map(lambda x: x.strip(), list)"
            },
            "type": "function"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "file_open",
                    "second_doc": "\"\"\"\nOpens a file based on the type of URL provided in the request, delegating to the appropriate handler for remote or local resources. This enables seamless access regardless of whether the file is located remotely or on the local system.\n\nArgs:\n    req: The request object containing information about the file to be opened, including its URL and type.\n\nReturns:\n    The result of opening the file, either by delegating to the parent handler for remote (FTP) URLs or by handling the local file directly.\n\"\"\"",
                    "source_code": "url = req.get_selector()\n        if url[:2] == '//' and url[2:3] != '/':\n            req.type = 'ftp'\n            return self.parent.open(req)\n        else:\n            return self.open_local_file(req)"
                },
                {
                    "docstring": null,
                    "method_name": "get_names",
                    "second_doc": "\"\"\"\nRetrieve and cache local machine network names, which may be required for consistent environment-specific processing.\n\nArgs:\n    None\n\nReturns:\n    tuple: A tuple containing the local host IP address resolved from 'localhost' and the current machine's hostname.\n\"\"\"",
                    "source_code": "if FileHandler.names is None:\n            FileHandler.names = (socket.gethostbyname('localhost'),\n                                 socket.gethostbyname(socket.gethostname()))\n        return FileHandler.names"
                },
                {
                    "docstring": null,
                    "method_name": "open_local_file",
                    "second_doc": "\"\"\"\nOpens a local file specified by a URL request if and only if the file is accessible from the local host. Constructs appropriate HTTP-style headers for the file, including MIME type, size, and last-modified timestamp, to allow the file to be read and transferred in a way compatible with URL handling workflows. This behavior ensures secure and controlled file access by validating that the request originates from the local system.\n\nArgs:\n    req: The URL request object containing information about the file to be opened.\n\nReturns:\n    addinfourl: A file-like object with reading capability and associated HTTP-style headers, suitable for use in URL-based file operations.\n\nRaises:\n    URLError: If the requested file is not on the local host or access is otherwise unauthorized.\n\"\"\"",
                    "source_code": "host = req.get_host()\n        file = req.get_selector()\n        localfile = url2pathname(file)\n        stats = os.stat(localfile)\n        size = stats[stat.ST_SIZE]\n        modified = rfc822.formatdate(stats[stat.ST_MTIME])\n        mtype = mimetypes.guess_type(file)[0]\n        stats = os.stat(localfile)\n        headers = mimetools.Message(StringIO(\n            'Content-Type: %s\\nContent-Length: %d\\nLast-modified: %s\\n' %\n            (mtype or 'text/plain', size, modified)))\n        if host:\n            host, port = splitport(host)\n        if not host or \\\n           (not port and socket.gethostbyname(host) in self.get_names()):\n            return addinfourl(open(localfile, 'rb'),\n                              headers, 'file:'+file)\n        raise URLError('file not on local host')"
                }
            ],
            "name": "FileHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "ftp_open",
                    "second_doc": "\"\"\"\nOpens an FTP connection to retrieve a file or directory listing specified by the request, handling network resolution, directory navigation, and appropriate data type selection for content retrieval.\n\nArgs:\n    req: A request object containing URL and selector details needed to identify the FTP resource.\n\nReturns:\n    An addinfourl object containing a file-like stream for the FTP resource and associated HTTP-style headers, making the response consumable by higher-level code components.\n\nRaises:\n    IOError: If no host is specified or a general FTP error occurs.\n    URLError: If the host cannot be resolved.\n\"\"\"",
                    "source_code": "host = req.get_host()\n        if not host:\n            raise IOError, ('ftp error', 'no host given')\n        # XXX handle custom username & password\n        try:\n            host = socket.gethostbyname(host)\n        except socket.error, msg:\n            raise URLError(msg)\n        host, port = splitport(host)\n        if port is None:\n            port = ftplib.FTP_PORT\n        path, attrs = splitattr(req.get_selector())\n        path = unquote(path)\n        dirs = path.split('/')\n        dirs, file = dirs[:-1], dirs[-1]\n        if dirs and not dirs[0]:\n            dirs = dirs[1:]\n        user = passwd = '' # XXX\n        try:\n            fw = self.connect_ftp(user, passwd, host, port, dirs)\n            type = file and 'I' or 'D'\n            for attr in attrs:\n                attr, value = splitattr(attr)\n                if attr.lower() == 'type' and \\\n                   value in ('a', 'A', 'i', 'I', 'd', 'D'):\n                    type = value.upper()\n            fp, retrlen = fw.retrfile(file, type)\n            headers = \"\"\n            mtype = mimetypes.guess_type(req.get_full_url())[0]\n            if mtype:\n                headers += \"Content-Type: %s\\n\" % mtype\n            if retrlen is not None and retrlen >= 0:\n                headers += \"Content-Length: %d\\n\" % retrlen\n            sf = StringIO(headers)\n            headers = mimetools.Message(sf)\n            return addinfourl(fp, headers, req.get_full_url())\n        except ftplib.all_errors, msg:\n            raise IOError, ('ftp error', msg), sys.exc_info()[2]"
                },
                {
                    "docstring": null,
                    "method_name": "connect_ftp",
                    "second_doc": "\"\"\"\nEstablishes and returns an FTP connection using the provided user credentials, host information, and directory settings.\n\nArgs:\n    user (str): The username for the FTP connection.\n    passwd (str): The password for the FTP connection.\n    host (str): The FTP server host address.\n    port (int): The port to connect to on the FTP server.\n    dirs (list): The list of directories to initialize upon connection.\n\nReturns:\n    ftpwrapper: An initialized FTP connection object.\n\nWhy:\n    This method creates an FTP connection object so that the program can access and process source code files stored remotely, facilitating further code analysis and manipulation tasks.\n\"\"\"",
                    "source_code": "fw = ftpwrapper(user, passwd, host, port, dirs)\n##        fw.ftp.set_debuglevel(1)\n        return fw"
                }
            ],
            "name": "FTPHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "__init__",
                    "second_doc": "\"\"\"\nInitializes internal data structures for managing cached connections and tracking their usage.\n\nArgs:\n    None\n\nReturns:\n    None\n\nThis method sets up default attributes to efficiently manage resource usage and optimize subsequent access to previously processed data.\n\"\"\"",
                    "source_code": "self.cache = {}\n        self.timeout = {}\n        self.soonest = 0\n        self.delay = 60\n        self.max_conns = 16"
                },
                {
                    "docstring": null,
                    "method_name": "setTimeout",
                    "second_doc": "\"\"\"\nSets the delay interval for cache operations, controlling how long the handler should wait before acting.\n\nArgs:\n    t (float): The delay time in seconds to be set for cache operations.\n\nReturns:\n    None\n\nThis method allows dynamic adjustment of cache handling timing, which can help balance responsiveness with resource management.\n\"\"\"",
                    "source_code": "self.delay = t"
                },
                {
                    "docstring": null,
                    "method_name": "setMaxConns",
                    "second_doc": "\"\"\"\nSets the maximum number of concurrent connections allowed for this handler.\n\nThis method is used to control resource usage and ensure optimal performance when managing multiple FTP connections.\n\nArgs:\n    m (int): The maximum number of allowed concurrent connections.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "self.max_conns = m"
                },
                {
                    "docstring": null,
                    "method_name": "connect_ftp",
                    "second_doc": "\"\"\"\nEstablishes and manages cached FTP connections to avoid redundant connection overhead and improve efficiency when accessing network file systems.\n\nArgs:\n    user (str): The username for FTP authentication.\n    passwd (str): The password for FTP authentication.\n    host (str): The FTP server host.\n    port (int): The FTP server port.\n    dirs (list): List of directory paths to initialize for the connection.\n\nReturns:\n    ftpwrapper: A cached or newly established FTP wrapper object for the given parameters.\n\nWhy:\n    This method caches active FTP connections to reduce unnecessary reconnections and manage connection timeouts, thereby optimizing resource usage and access speed for repeated FTP operations.\n\"\"\"",
                    "source_code": "key = user, passwd, host, port\n        if self.cache.has_key(key):\n            self.timeout[key] = time.time() + self.delay\n        else:\n            self.cache[key] = ftpwrapper(user, passwd, host, port, dirs)\n            self.timeout[key] = time.time() + self.delay\n        self.check_cache()\n        return self.cache[key]"
                },
                {
                    "docstring": null,
                    "method_name": "check_cache",
                    "second_doc": "\"\"\"\nChecks and removes expired or excess items from the connection cache to ensure efficient resource management and prevent stale connections.\n\nArgs:\n    None\n\nReturns:\n    None\n\nThis method iterates through cached connections, closing and removing any that have timed out or exceed the allowed cache size. This helps keep the cache up-to-date and avoids resource leaks by enforcing connection timeouts and the maximum connection limit.\n\"\"\"",
                    "source_code": "t = time.time()\n        if self.soonest <= t:\n            for k, v in self.timeout.items():\n                if v < t:\n                    self.cache[k].close()\n                    del self.cache[k]\n                    del self.timeout[k]\n        self.soonest = min(self.timeout.values())\n\n        # then check the size\n        if len(self.cache) == self.max_conns:\n            for k, v in self.timeout.items():\n                if v == self.soonest:\n                    del self.cache[k]\n                    del self.timeout[k]\n                    break\n            self.soonest = min(self.timeout.values())"
                }
            ],
            "name": "CacheFTPHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "gopher_open",
                    "second_doc": "\"\"\"\nHandles the process of opening a connection to a Gopher server based on the supplied request, extracting and decoding the host and selector information, and managing query parameters as needed in order to retrieve the appropriate response stream.\n\nArgs:\n    req: The request object containing the Gopher URL and parameters.\n\nReturns:\n    An addinfourl object wrapping the file-like response from the Gopher server, with no headers and the full request URL.\n\nRaises:\n    GopherError: If no host is provided in the request.\n    \nWhy:\n    This method performs these operations to abstract the retrieval and decoding complexities of Gopher resources, enabling higher-level components to treat Gopher responses in a consistent and streamlined manner.\n\"\"\"",
                    "source_code": "host = req.get_host()\n        if not host:\n            raise GopherError('no host given')\n        host = unquote(host)\n        selector = req.get_selector()\n        type, selector = splitgophertype(selector)\n        selector, query = splitquery(selector)\n        selector = unquote(selector)\n        if query:\n            query = unquote(query)\n            fp = gopherlib.send_query(selector, query, host)\n        else:\n            fp = gopherlib.send_selector(selector, host)\n        return addinfourl(fp, noheaders(), req.get_full_url())"
                }
            ],
            "name": "GopherHandler",
            "type": "class"
        },
        {
            "methods": [
                {
                    "docstring": null,
                    "method_name": "add_proxy_handler",
                    "second_doc": "\"\"\"\nAdds a given proxy handler to the internal list of proxy handlers used by the opener.\n\nArgs:\n    ph: The proxy handler instance to be added to the opener's handler list.\n\nReturns:\n    None\n\nThis method updates the internal handler list to ensure that HTTP requests made through the opener can be routed through newly specified proxies as needed, enhancing flexibility and control over network interactions.\n\"\"\"",
                    "source_code": "self.proxy_handlers = self.proxy_handlers + [ph]"
                },
                {
                    "docstring": null,
                    "method_name": "add_handler",
                    "second_doc": "\"\"\"\nAdds a new handler to the list of existing handlers for this instance.\n\nArgs:\n    h: The handler object to be added.\n\nReturns:\n    None\n\nWhy:\n    By maintaining an up-to-date collection of handlers, the system can properly process and manage various operations required during code analysis and transformation, supporting the dynamic extension of its capabilities.\n\"\"\"",
                    "source_code": "self.handlers = self.handlers + [h]"
                },
                {
                    "docstring": null,
                    "method_name": "replace_handler",
                    "second_doc": "\"\"\"\nReplaces the current handler with a new one within the opener factory setup, ensuring that code analysis processes interact with the updated logic for file or network interactions.\n\nArgs:\n    handler: The handler instance to use as a replacement for the existing one.\n\nReturns:\n    None\n\"\"\"",
                    "source_code": "pass"
                },
                {
                    "docstring": null,
                    "method_name": "build_opener",
                    "second_doc": "\"\"\"\nConstructs and returns an OpenerDirector instance with the configured proxy handlers added. This method ensures that all user-specified proxy handlers are appropriately instantiated and registered, enabling proper HTTP request handling and customization as needed for analyzing code relationships.\n\nArgs:\n    None\n\nReturns:\n    OpenerDirector: An opener object configured with the specified proxy handlers.\n\"\"\"",
                    "source_code": "opener = OpenerDirector()\n        for ph in self.proxy_handlers:\n            if inspect.isclass(ph):\n                ph = ph()\n            opener.add_handler(ph)"
                }
            ],
            "name": "OpenerFactory",
            "type": "class"
        }
    ]
}